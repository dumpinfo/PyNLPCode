{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Character based text generation using a GRU </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/i346047/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/Users/i346047/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import codecs\n",
    "import re\n",
    "EMBED_DIMENSION = 50\n",
    "HIDDEN_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52657, 1) (52657, 1)\n"
     ]
    }
   ],
   "source": [
    "with codecs.open('/tmp/kernel.txt', 'r', encoding='utf-8', errors='ignore') as kernel_file:\n",
    "    raw_text = kernel_file.read()\n",
    "kernel_words = re.split('(\\-\\>)|([\\-\\>+\\=\\<\\/\\&\\|\\(\\)\\:\\*])',raw_text)\n",
    "kernel_words = [w for w in kernel_words if w is not None]\n",
    "kernel_words = kernel_words[0:300000]\n",
    "kernel_words = set(kernel_words)\n",
    "kword_to_int = dict((word, i) for i, word in enumerate(kernel_words))\n",
    "int_to_kword = dict((i, word) for i, word in enumerate(kernel_words))\n",
    "v_size = len(kword_to_int)\n",
    "kword_to_int['<UNK>'] = v_size\n",
    "int_to_kword[v_size] = '<UNK>'\n",
    "v_size += 1\n",
    "X_train = [kword_to_int[word] for word in kernel_words]\n",
    "y_train = X_train[1:]\n",
    "y_train.append(kword_to_int['<UNK>'])\n",
    "X_train = np.asarray(X_train)\n",
    "y_train = np.asarray(y_train)\n",
    "X_train = np.expand_dims(X_train,axis=1)\n",
    "y_train = np.expand_dims(y_train,axis=1)\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def estimator_spec_for_generation(flayer_op, lbls, md):\n",
    "    preds_cls = tf.argmax(flayer_op, 1)\n",
    "    if md == tf.estimator.ModeKeys.PREDICT:\n",
    "        prev_op = tf.reshape(flayer_op, [-1, 1, v_size])[:, -1, :]\n",
    "        preds_op = tf.nn.softmax(prev_op)\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "        mode=md,\n",
    "        predictions={\n",
    "            'preds_probs': preds_op\n",
    "        })\n",
    "    trng_loss = tf.losses.sparse_softmax_cross_entropy(labels=lbls, logits=flayer_op)\n",
    "    if md == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "        trng_op = optimizer.minimize(trng_loss, global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(md, loss=trng_loss, train_op=trng_op)\n",
    "    ev_met_ops = {'accy': tf.metrics.accuracy(labels=lbls, predictions=preds_cls)}\n",
    "    return tf.estimator.EstimatorSpec(md, loss=trng_loss, train_op=trng_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rnn_model_fn(features, labels, mode):\n",
    "    embedding = tf.Variable(tf.truncated_normal([v_size, EMBED_DIMENSION], \n",
    "                                                    stddev=1.0/np.sqrt(EMBED_DIMENSION)), \n",
    "                                name=\"word_embeddings\")\n",
    "    word_emb = tf.nn.embedding_lookup(embedding, features['word'])\n",
    "    rnn_cell = tf.nn.rnn_cell.GRUCell(HIDDEN_SIZE)\n",
    "    \n",
    "    outputs, _ = tf.nn.dynamic_rnn(rnn_cell, word_emb, dtype=tf.float32)\n",
    "    outputs = tf.reshape(outputs, [-1, HIDDEN_SIZE])\n",
    "    flayer_op = tf.layers.dense(outputs, v_size, name=\"linear\")\n",
    "    return estimator_spec_for_generation(flayer_op, labels, mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x119822390>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 10, '_save_checkpoints_secs': 600, '_log_step_count_steps': 10, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/models/'}\n"
     ]
    }
   ],
   "source": [
    "run_config = tf.contrib.learn.RunConfig()\n",
    "run_config = run_config.replace(model_dir='/tmp/models/',save_summary_steps=10,log_step_count_steps=10)\n",
    "generator = tf.estimator.Estimator(model_fn=rnn_model_fn,config=run_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/models/model.ckpt.\n",
      "INFO:tensorflow:loss = 10.871534, step = 1\n",
      "INFO:tensorflow:global_step/sec: 0.64247\n",
      "INFO:tensorflow:global_step/sec: 0.620477\n",
      "INFO:tensorflow:global_step/sec: 0.617585\n",
      "INFO:tensorflow:global_step/sec: 0.623787\n",
      "INFO:tensorflow:global_step/sec: 0.613455\n",
      "INFO:tensorflow:global_step/sec: 0.624856\n",
      "INFO:tensorflow:global_step/sec: 0.623827\n",
      "INFO:tensorflow:global_step/sec: 0.625256\n",
      "INFO:tensorflow:global_step/sec: 0.61646\n",
      "INFO:tensorflow:global_step/sec: 0.627149\n",
      "INFO:tensorflow:loss = 10.203493, step = 101 (160.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.631025\n",
      "INFO:tensorflow:global_step/sec: 0.630481\n",
      "INFO:tensorflow:global_step/sec: 0.603987\n",
      "INFO:tensorflow:global_step/sec: 0.609417\n",
      "INFO:tensorflow:global_step/sec: 0.615121\n",
      "INFO:tensorflow:global_step/sec: 0.627453\n",
      "INFO:tensorflow:global_step/sec: 0.631844\n",
      "INFO:tensorflow:global_step/sec: 0.620623\n",
      "INFO:tensorflow:global_step/sec: 0.628916\n",
      "INFO:tensorflow:global_step/sec: 0.623621\n",
      "INFO:tensorflow:loss = 2.2286625, step = 201 (160.743 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.623631\n",
      "INFO:tensorflow:global_step/sec: 0.625705\n",
      "INFO:tensorflow:global_step/sec: 0.621712\n",
      "INFO:tensorflow:global_step/sec: 0.600219\n",
      "INFO:tensorflow:global_step/sec: 0.606918\n",
      "INFO:tensorflow:global_step/sec: 0.589141\n",
      "INFO:tensorflow:global_step/sec: 0.602502\n",
      "INFO:tensorflow:global_step/sec: 0.591608\n",
      "INFO:tensorflow:global_step/sec: 0.592844\n",
      "INFO:tensorflow:Saving checkpoints for 300 into /tmp/models/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.01162095.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x11978ec18>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={'word': X_train},\n",
    "      y=y_train,\n",
    "      batch_size=1024,\n",
    "      num_epochs=None,\n",
    "      shuffle=True)\n",
    "generator.train(input_fn=train_input_fn, steps=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/models/model.ckpt-300\n",
      "INFO:tensorflow:Restoring parameters from /tmp/models/model.ckpt-300\n",
      "INFO:tensorflow:Restoring parameters from /tmp/models/model.ckpt-300\n",
      "INFO:tensorflow:Restoring parameters from /tmp/models/model.ckpt-300\n",
      "INFO:tensorflow:Restoring parameters from /tmp/models/model.ckpt-300\n",
      "INFO:tensorflow:Restoring parameters from /tmp/models/model.ckpt-300\n",
      "INFO:tensorflow:Restoring parameters from /tmp/models/model.ckpt-300\n",
      "INFO:tensorflow:Restoring parameters from /tmp/models/model.ckpt-300\n",
      "INFO:tensorflow:Restoring parameters from /tmp/models/model.ckpt-300\n",
      "INFO:tensorflow:Restoring parameters from /tmp/models/model.ckpt-300\n",
      "INFO:tensorflow:Restoring parameters from /tmp/models/model.ckpt-300\n",
      "INFO:tensorflow:Restoring parameters from /tmp/models/model.ckpt-300\n",
      "INFO:tensorflow:Restoring parameters from /tmp/models/model.ckpt-300\n",
      "INFO:tensorflow:Restoring parameters from /tmp/models/model.ckpt-300\n",
      "INFO:tensorflow:Restoring parameters from /tmp/models/model.ckpt-300\n",
      "INFO:tensorflow:Restoring parameters from /tmp/models/model.ckpt-300\n",
      "INFO:tensorflow:Restoring parameters from /tmp/models/model.ckpt-300\n",
      "INFO:tensorflow:Restoring parameters from /tmp/models/model.ckpt-300\n",
      "INFO:tensorflow:Restoring parameters from /tmp/models/model.ckpt-300\n",
      "INFO:tensorflow:Restoring parameters from /tmp/models/model.ckpt-300\n",
      "INFO:tensorflow:Restoring parameters from /tmp/models/model.ckpt-300\n",
      "INFO:tensorflow:Restoring parameters from /tmp/models/model.ckpt-300\n",
      "INFO:tensorflow:Restoring parameters from /tmp/models/model.ckpt-300\n",
      "INFO:tensorflow:Restoring parameters from /tmp/models/model.ckpt-300\n",
      "INFO:tensorflow:Restoring parameters from /tmp/models/model.ckpt-300\n",
      "INFO:tensorflow:Restoring parameters from /tmp/models/model.ckpt-300\n",
      "INFO:tensorflow:Restoring parameters from /tmp/models/model.ckpt-300\n",
      "INFO:tensorflow:Restoring parameters from /tmp/models/model.ckpt-300\n",
      "INFO:tensorflow:Restoring parameters from /tmp/models/model.ckpt-300\n",
      "INFO:tensorflow:Restoring parameters from /tmp/models/model.ckpt-300\n",
      "INFO:tensorflow:Restoring parameters from /tmp/models/model.ckpt-300\n",
      "INFO:tensorflow:Restoring parameters from /tmp/models/model.ckpt-300\n",
      "INFO:tensorflow:Restoring parameters from /tmp/models/model.ckpt-300\n",
      "INFO:tensorflow:Restoring parameters from /tmp/models/model.ckpt-300\n",
      "INFO:tensorflow:Restoring parameters from /tmp/models/model.ckpt-300\n",
      "INFO:tensorflow:Restoring parameters from /tmp/models/model.ckpt-300\n",
      "INFO:tensorflow:Restoring parameters from /tmp/models/model.ckpt-300\n",
      "INFO:tensorflow:Restoring parameters from /tmp/models/model.ckpt-300\n",
      "INFO:tensorflow:Restoring parameters from /tmp/models/model.ckpt-300\n",
      "INFO:tensorflow:Restoring parameters from /tmp/models/model.ckpt-300\n"
     ]
    }
   ],
   "source": [
    "maxlen = 40\n",
    "next_x = X_train[0:60]\n",
    "text = \"\".join([int_to_kword[word] for word in next_x.flatten()])\n",
    "for i in range(maxlen):\n",
    "    test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={'word': next_x},\n",
    "      num_epochs=1,\n",
    "      shuffle=False)\n",
    "    predictions = generator.predict(input_fn=test_input_fn)\n",
    "    predictions = list(predictions)\n",
    "    word = int_to_kword[np.argmax(predictions[-1]['preds_probs'])]\n",
    "    text = text +  word\n",
    "    next_x = np.concatenate((next_x,[[kword_to_int[word]]]))\n",
    "    next_x = next_x[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " for single ops connected being NULL, or CONFIG_DYNAMIC_FTRACE_WITH_REGS.\n",
      " \n",
      "\t\tset_current_stateevent;\n",
      "\tstruct trace_mmiotrace_map  tracing_map_elt_allocops,\n",
      "\t\t\t\t    struct event_trigger_data  \"migration;\n",
      "\t\t}\n",
      "\t}\n",
      "\twakelocks_gc_count  NULL;\n",
      "\tspin_lock_irqstart,\n",
      "\t\t\t        store_gcov_u64  trace_output_rawevent,\n",
      "\t\t\t\t      struct event_filter \"r\n",
      "\t     child\n",
      "\t\tdpm_resume_end\n",
      "\t\tparam.args[i] entry, tmp, ;\n",
      "\trcu_report_dead Note, CONFIG_DYNAMIC_FTRACE_WITH_REGS expects a full regs to be saved.\n",
      " test_nop_accept, TRACE_NOP_OPT_ACCEPT\n",
      "\t\treturn t_probe_showouter_duration,\n",
      "\t\t\t \n",
      "void pm_qos_remove_request any registered driver indicates it needs a VT switch\n",
      " \n",
      "void free_ftrace_func_mappercurrent_func  {\n",
      "\t\tchar comm[TASK_COMM_LEN];\n",
      "\n",
      "\t\ttrace_find_cmdlinenamed_list\"Compressing and saving image data sechdrs;\n",
      "\tchar  \"network_latency\",\n",
      "};\n",
      "\n",
      "\n",
      "static BLOCKING_NOTIFIER_HEAD The command that needs to be done\n",
      "  ops;\n",
      "\topsor required key missing  @task   ftrace_start_up is true if we want ftrace running  then we bypass the irq check.\n",
      "\t ppsfreq;\n",
      "\ttx32.jitter call, char ;\n",
      "\n",
      "static int blk_trace_remove_queue Initialize POSIX timer handling for a thread group.\n",
      "  PAGE_SHIFT;\n",
      "\t\tif !rb_threads[cpu]s, const struct pci_dev ;\n",
      "\tcheck_mm the filter_hash does not exist or is empty,\n",
      " \n",
      "\t\treturn NULL;\n",
      "\n",
      "\tmemsetkexec_image;\n",
      "struct kimage ;\n",
      "}\n",
      "\n",
      "power_attr_rostruct hist_field module_add_modinfo_attrs Fake ip  data;\n",
      "\tstruct page \n",
      "{\n",
      "\treturn arg ? GFP_ATOMIC  PM_SUSPEND_ON\n",
      "\t\tgoto fail_free_buffers;\n",
      "\n",
      "\tret  sec;\n",
      "\t}\n",
      "\n",
      "\tkfree tracing_nsecs_write No functions to be traced?\\n\" Duplicate table of functions. refconsumer.ret_handler  find_regsetsavedcmd_temp\n",
      "\t\t\treturn SEQ_START_TOKEN;\n",
      "\t\tn PR_TIMING_STATISTICAL;\n",
      "\t\tbreak;\n",
      "\tcase PR_SET_TIMING;\n",
      "}\n",
      "\n",
      "static struct ftrace_ops trace_ops __initdata   into them directly.\n",
      "\t !is_sampling_eventholders_dir, mod MIN_NICE can be offsets in the trace data.\n",
      "  to the buffer after this will fail and return NULL.\n",
      "  ring_buffer_record_enable_cpu  {\n",
      "\t\tarea[pos] ;\n",
      "\n",
      "#ifdef CONFIG_SUSPEND\n",
      "\tif  hist_field_u16;\n",
      "\t\tbreak;\n",
      "\tcase 1 representing a file path of format and ;\n",
      "\n",
      "#endif ;\n",
      "\t\tgoto out;\n",
      "\t}\n",
      "\n",
      "\tftrace_graph_return  Pipe buffer operations for a buffer.  val;\n",
      "\tarch_spin_unlock If we fail, we do not register this tracer.\n",
      "\t \n",
      "\treturn ret;\n",
      "}\n",
      "\n",
      "static int create_hist_fields\n",
      "\t\t\tbreak;\n",
      "\t}\n",
      "\n",
      "\tif elt;\n",
      "\t\ttarget_elt \n",
      "\n",
      "\n",
      "#undef DEBUG\n",
      "\n",
      "#include ;\n",
      "\t}\n",
      "\n",
      "\twakelocks_lru_most_recentENOMEM;\n",
      "\t\t\tbreak;\n",
      "\t\t}\n",
      "\n",
      "\t\tref;\n",
      "\t}\n",
      "\n",
      "\trb_reader_unlockaddr,\n",
      "\t\t       entry;\n",
      "\tevent_call if an organisation operation is in\n",
      "\t  'u' \n",
      "\t\thwlat_tracer_start\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
