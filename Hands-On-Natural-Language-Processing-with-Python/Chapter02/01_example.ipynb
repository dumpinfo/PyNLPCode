{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Movie review classification with NLTK </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import nltk\n",
    "from nltk import NaiveBayesClassifier\n",
    "from nltk.corpus import movie_reviews\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cats = movie_reviews.categories()\n",
    "reviews = []\n",
    "for cat in cats:\n",
    "    for fid in movie_reviews.fileids(cat):\n",
    "        review = (list(movie_reviews.words(fid)),cat)\n",
    "        reviews.append(review)\n",
    "random.shuffle(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_wd_in_reviews = nltk.FreqDist(wd.lower() for wd in movie_reviews.words())\n",
    "top_wd_in_reviews = [list(wds) for wds in zip(*all_wd_in_reviews.most_common(2000))][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ext_ft(review,top_words):\n",
    "    review_wds = set(review)\n",
    "    ft = {}\n",
    "    for wd in top_words:\n",
    "        ft['word_present({})'.format(wd)] = (wd in review_wds)\n",
    "    return ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(ext_ft(d,top_wd_in_reviews), c) for (d,c) in reviews]\n",
    "train_set, test_set = featuresets[200:], featuresets[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.79\n"
     ]
    }
   ],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "    word_present(seagal) = True              neg : pos    =     12.5 : 1.0\n",
      "word_present(outstanding) = True              pos : neg    =     10.1 : 1.0\n",
      "     word_present(mulan) = True              pos : neg    =      8.9 : 1.0\n",
      "word_present(wonderfully) = True              pos : neg    =      7.3 : 1.0\n",
      "    word_present(wasted) = True              neg : pos    =      6.1 : 1.0\n",
      "     word_present(awful) = True              neg : pos    =      6.1 : 1.0\n",
      "    word_present(poorly) = True              neg : pos    =      5.8 : 1.0\n",
      "     word_present(flynt) = True              pos : neg    =      5.6 : 1.0\n",
      "      word_present(lame) = True              neg : pos    =      5.5 : 1.0\n",
      "     word_present(damon) = True              pos : neg    =      5.4 : 1.0\n",
      "word_present(ridiculous) = True              neg : pos    =      5.3 : 1.0\n",
      "       word_present(era) = True              pos : neg    =      5.1 : 1.0\n",
      "      word_present(jedi) = True              pos : neg    =      4.9 : 1.0\n",
      "   word_present(unfunny) = True              neg : pos    =      4.8 : 1.0\n",
      "     word_present(waste) = True              neg : pos    =      4.7 : 1.0\n",
      "     word_present(worst) = True              neg : pos    =      4.7 : 1.0\n",
      " word_present(fantastic) = True              pos : neg    =      4.5 : 1.0\n",
      "     word_present(bland) = True              neg : pos    =      4.4 : 1.0\n",
      " word_present(laughable) = True              neg : pos    =      4.3 : 1.0\n",
      "      word_present(zero) = True              neg : pos    =      4.0 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_vectorizer=None\n",
    "def get_train_test(train_set,test_set):\n",
    "    global dict_vectorizer\n",
    "    dict_vectorizer = DictVectorizer(sparse=False)\n",
    "    X_train, y_train = zip(*train_set)\n",
    "    X_train = dict_vectorizer.fit_transform(X_train)\n",
    "    X_test,y_test = zip(*test_set)\n",
    "    X_test = dict_vectorizer.transform(X_test)\n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=4,\n",
       "            oob_score=False, random_state=10, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = get_train_test(train_set,test_set)\n",
    "rf = RandomForestClassifier(n_estimators=100,n_jobs=4,random_state=10)\n",
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.785\n"
     ]
    }
   ],
   "source": [
    "preds = rf.predict(X_test)\n",
    "print(accuracy_score(y_test,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords_list = stopwords.words('english')\n",
    "all_words_in_reviews = nltk.FreqDist(word.lower() for word in movie_reviews.words() if word not in stopwords_list)\n",
    "top_words_in_reviews = [list(words) for words in zip(*all_words_in_reviews.most_common(2000))][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featuresets = [(ext_ft(d,top_words_in_reviews), c) for (d,c) in reviews]\n",
    "train_set, test_set = featuresets[200:], featuresets[:200]\n",
    "X_train,X_test,y_train,y_test = get_train_test(train_set,test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=4,\n",
       "            oob_score=False, random_state=10, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100,n_jobs=4,random_state=10)\n",
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.825\n"
     ]
    }
   ],
   "source": [
    "preds = rf.predict(X_test)\n",
    "print(accuracy_score(y_test,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('word_present(bad)', 0.012904816953952729), ('word_present(boring)', 0.006797056379259946), ('word_present(stupid)', 0.006742453545126172), ('word_present(awful)', 0.00605732124427093), ('word_present(worst)', 0.005618499631730539), ('word_present(waste)', 0.005091242651240423), ('word_present(supposed)', 0.005019844359438753), ('word_present(excellent)', 0.005002846831984908), ('word_present(mess)', 0.004735341799753426), ('word_present(wasted)', 0.004477280752464545), ('word_present(ridiculous)', 0.00435578373608493), ('word_present(lame)', 0.00404257877140679), ('word_present(also)', 0.003663095965733155), ('word_present(others)', 0.0035194019538410553), ('word_present(dull)', 0.003464806019875671), ('word_present(plot)', 0.0034406946286116035), ('word_present(nothing)', 0.0033285487918061265), ('word_present(performances)', 0.003286015291474251), ('word_present(outstanding)', 0.0032708132090801516), ('word_present(memorable)', 0.003265718932501386)]\n"
     ]
    }
   ],
   "source": [
    "features_list = zip(dict_vectorizer.get_feature_names(),rf.feature_importances_)\n",
    "features_list = sorted(features_list, key=lambda x: x[1], reverse=True)\n",
    "print(features_list[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
