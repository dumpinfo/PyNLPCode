{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class str in module __builtin__:\n",
      "\n",
      "class str(basestring)\n",
      " |  str(object='') -> string\n",
      " |  \n",
      " |  Return a nice string representation of the object.\n",
      " |  If the argument is a string, the return value is the same object.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      str\n",
      " |      basestring\n",
      " |      object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __add__(...)\n",
      " |      x.__add__(y) <==> x+y\n",
      " |  \n",
      " |  __contains__(...)\n",
      " |      x.__contains__(y) <==> y in x\n",
      " |  \n",
      " |  __eq__(...)\n",
      " |      x.__eq__(y) <==> x==y\n",
      " |  \n",
      " |  __format__(...)\n",
      " |      S.__format__(format_spec) -> string\n",
      " |      \n",
      " |      Return a formatted version of S as described by format_spec.\n",
      " |  \n",
      " |  __ge__(...)\n",
      " |      x.__ge__(y) <==> x>=y\n",
      " |  \n",
      " |  __getattribute__(...)\n",
      " |      x.__getattribute__('name') <==> x.name\n",
      " |  \n",
      " |  __getitem__(...)\n",
      " |      x.__getitem__(y) <==> x[y]\n",
      " |  \n",
      " |  __getnewargs__(...)\n",
      " |  \n",
      " |  __getslice__(...)\n",
      " |      x.__getslice__(i, j) <==> x[i:j]\n",
      " |      \n",
      " |      Use of negative indices is not supported.\n",
      " |  \n",
      " |  __gt__(...)\n",
      " |      x.__gt__(y) <==> x>y\n",
      " |  \n",
      " |  __hash__(...)\n",
      " |      x.__hash__() <==> hash(x)\n",
      " |  \n",
      " |  __le__(...)\n",
      " |      x.__le__(y) <==> x<=y\n",
      " |  \n",
      " |  __len__(...)\n",
      " |      x.__len__() <==> len(x)\n",
      " |  \n",
      " |  __lt__(...)\n",
      " |      x.__lt__(y) <==> x<y\n",
      " |  \n",
      " |  __mod__(...)\n",
      " |      x.__mod__(y) <==> x%y\n",
      " |  \n",
      " |  __mul__(...)\n",
      " |      x.__mul__(n) <==> x*n\n",
      " |  \n",
      " |  __ne__(...)\n",
      " |      x.__ne__(y) <==> x!=y\n",
      " |  \n",
      " |  __repr__(...)\n",
      " |      x.__repr__() <==> repr(x)\n",
      " |  \n",
      " |  __rmod__(...)\n",
      " |      x.__rmod__(y) <==> y%x\n",
      " |  \n",
      " |  __rmul__(...)\n",
      " |      x.__rmul__(n) <==> n*x\n",
      " |  \n",
      " |  __sizeof__(...)\n",
      " |      S.__sizeof__() -> size of S in memory, in bytes\n",
      " |  \n",
      " |  __str__(...)\n",
      " |      x.__str__() <==> str(x)\n",
      " |  \n",
      " |  capitalize(...)\n",
      " |      S.capitalize() -> string\n",
      " |      \n",
      " |      Return a copy of the string S with only its first character\n",
      " |      capitalized.\n",
      " |  \n",
      " |  center(...)\n",
      " |      S.center(width[, fillchar]) -> string\n",
      " |      \n",
      " |      Return S centered in a string of length width. Padding is\n",
      " |      done using the specified fill character (default is a space)\n",
      " |  \n",
      " |  count(...)\n",
      " |      S.count(sub[, start[, end]]) -> int\n",
      " |      \n",
      " |      Return the number of non-overlapping occurrences of substring sub in\n",
      " |      string S[start:end].  Optional arguments start and end are interpreted\n",
      " |      as in slice notation.\n",
      " |  \n",
      " |  decode(...)\n",
      " |      S.decode([encoding[,errors]]) -> object\n",
      " |      \n",
      " |      Decodes S using the codec registered for encoding. encoding defaults\n",
      " |      to the default encoding. errors may be given to set a different error\n",
      " |      handling scheme. Default is 'strict' meaning that encoding errors raise\n",
      " |      a UnicodeDecodeError. Other possible values are 'ignore' and 'replace'\n",
      " |      as well as any other name registered with codecs.register_error that is\n",
      " |      able to handle UnicodeDecodeErrors.\n",
      " |  \n",
      " |  encode(...)\n",
      " |      S.encode([encoding[,errors]]) -> object\n",
      " |      \n",
      " |      Encodes S using the codec registered for encoding. encoding defaults\n",
      " |      to the default encoding. errors may be given to set a different error\n",
      " |      handling scheme. Default is 'strict' meaning that encoding errors raise\n",
      " |      a UnicodeEncodeError. Other possible values are 'ignore', 'replace' and\n",
      " |      'xmlcharrefreplace' as well as any other name registered with\n",
      " |      codecs.register_error that is able to handle UnicodeEncodeErrors.\n",
      " |  \n",
      " |  endswith(...)\n",
      " |      S.endswith(suffix[, start[, end]]) -> bool\n",
      " |      \n",
      " |      Return True if S ends with the specified suffix, False otherwise.\n",
      " |      With optional start, test S beginning at that position.\n",
      " |      With optional end, stop comparing S at that position.\n",
      " |      suffix can also be a tuple of strings to try.\n",
      " |  \n",
      " |  expandtabs(...)\n",
      " |      S.expandtabs([tabsize]) -> string\n",
      " |      \n",
      " |      Return a copy of S where all tab characters are expanded using spaces.\n",
      " |      If tabsize is not given, a tab size of 8 characters is assumed.\n",
      " |  \n",
      " |  find(...)\n",
      " |      S.find(sub [,start [,end]]) -> int\n",
      " |      \n",
      " |      Return the lowest index in S where substring sub is found,\n",
      " |      such that sub is contained within S[start:end].  Optional\n",
      " |      arguments start and end are interpreted as in slice notation.\n",
      " |      \n",
      " |      Return -1 on failure.\n",
      " |  \n",
      " |  format(...)\n",
      " |      S.format(*args, **kwargs) -> string\n",
      " |      \n",
      " |      Return a formatted version of S, using substitutions from args and kwargs.\n",
      " |      The substitutions are identified by braces ('{' and '}').\n",
      " |  \n",
      " |  index(...)\n",
      " |      S.index(sub [,start [,end]]) -> int\n",
      " |      \n",
      " |      Like S.find() but raise ValueError when the substring is not found.\n",
      " |  \n",
      " |  isalnum(...)\n",
      " |      S.isalnum() -> bool\n",
      " |      \n",
      " |      Return True if all characters in S are alphanumeric\n",
      " |      and there is at least one character in S, False otherwise.\n",
      " |  \n",
      " |  isalpha(...)\n",
      " |      S.isalpha() -> bool\n",
      " |      \n",
      " |      Return True if all characters in S are alphabetic\n",
      " |      and there is at least one character in S, False otherwise.\n",
      " |  \n",
      " |  isdigit(...)\n",
      " |      S.isdigit() -> bool\n",
      " |      \n",
      " |      Return True if all characters in S are digits\n",
      " |      and there is at least one character in S, False otherwise.\n",
      " |  \n",
      " |  islower(...)\n",
      " |      S.islower() -> bool\n",
      " |      \n",
      " |      Return True if all cased characters in S are lowercase and there is\n",
      " |      at least one cased character in S, False otherwise.\n",
      " |  \n",
      " |  isspace(...)\n",
      " |      S.isspace() -> bool\n",
      " |      \n",
      " |      Return True if all characters in S are whitespace\n",
      " |      and there is at least one character in S, False otherwise.\n",
      " |  \n",
      " |  istitle(...)\n",
      " |      S.istitle() -> bool\n",
      " |      \n",
      " |      Return True if S is a titlecased string and there is at least one\n",
      " |      character in S, i.e. uppercase characters may only follow uncased\n",
      " |      characters and lowercase characters only cased ones. Return False\n",
      " |      otherwise.\n",
      " |  \n",
      " |  isupper(...)\n",
      " |      S.isupper() -> bool\n",
      " |      \n",
      " |      Return True if all cased characters in S are uppercase and there is\n",
      " |      at least one cased character in S, False otherwise.\n",
      " |  \n",
      " |  join(...)\n",
      " |      S.join(iterable) -> string\n",
      " |      \n",
      " |      Return a string which is the concatenation of the strings in the\n",
      " |      iterable.  The separator between elements is S.\n",
      " |  \n",
      " |  ljust(...)\n",
      " |      S.ljust(width[, fillchar]) -> string\n",
      " |      \n",
      " |      Return S left-justified in a string of length width. Padding is\n",
      " |      done using the specified fill character (default is a space).\n",
      " |  \n",
      " |  lower(...)\n",
      " |      S.lower() -> string\n",
      " |      \n",
      " |      Return a copy of the string S converted to lowercase.\n",
      " |  \n",
      " |  lstrip(...)\n",
      " |      S.lstrip([chars]) -> string or unicode\n",
      " |      \n",
      " |      Return a copy of the string S with leading whitespace removed.\n",
      " |      If chars is given and not None, remove characters in chars instead.\n",
      " |      If chars is unicode, S will be converted to unicode before stripping\n",
      " |  \n",
      " |  partition(...)\n",
      " |      S.partition(sep) -> (head, sep, tail)\n",
      " |      \n",
      " |      Search for the separator sep in S, and return the part before it,\n",
      " |      the separator itself, and the part after it.  If the separator is not\n",
      " |      found, return S and two empty strings.\n",
      " |  \n",
      " |  replace(...)\n",
      " |      S.replace(old, new[, count]) -> string\n",
      " |      \n",
      " |      Return a copy of string S with all occurrences of substring\n",
      " |      old replaced by new.  If the optional argument count is\n",
      " |      given, only the first count occurrences are replaced.\n",
      " |  \n",
      " |  rfind(...)\n",
      " |      S.rfind(sub [,start [,end]]) -> int\n",
      " |      \n",
      " |      Return the highest index in S where substring sub is found,\n",
      " |      such that sub is contained within S[start:end].  Optional\n",
      " |      arguments start and end are interpreted as in slice notation.\n",
      " |      \n",
      " |      Return -1 on failure.\n",
      " |  \n",
      " |  rindex(...)\n",
      " |      S.rindex(sub [,start [,end]]) -> int\n",
      " |      \n",
      " |      Like S.rfind() but raise ValueError when the substring is not found.\n",
      " |  \n",
      " |  rjust(...)\n",
      " |      S.rjust(width[, fillchar]) -> string\n",
      " |      \n",
      " |      Return S right-justified in a string of length width. Padding is\n",
      " |      done using the specified fill character (default is a space)\n",
      " |  \n",
      " |  rpartition(...)\n",
      " |      S.rpartition(sep) -> (head, sep, tail)\n",
      " |      \n",
      " |      Search for the separator sep in S, starting at the end of S, and return\n",
      " |      the part before it, the separator itself, and the part after it.  If the\n",
      " |      separator is not found, return two empty strings and S.\n",
      " |  \n",
      " |  rsplit(...)\n",
      " |      S.rsplit([sep [,maxsplit]]) -> list of strings\n",
      " |      \n",
      " |      Return a list of the words in the string S, using sep as the\n",
      " |      delimiter string, starting at the end of the string and working\n",
      " |      to the front.  If maxsplit is given, at most maxsplit splits are\n",
      " |      done. If sep is not specified or is None, any whitespace string\n",
      " |      is a separator.\n",
      " |  \n",
      " |  rstrip(...)\n",
      " |      S.rstrip([chars]) -> string or unicode\n",
      " |      \n",
      " |      Return a copy of the string S with trailing whitespace removed.\n",
      " |      If chars is given and not None, remove characters in chars instead.\n",
      " |      If chars is unicode, S will be converted to unicode before stripping\n",
      " |  \n",
      " |  split(...)\n",
      " |      S.split([sep [,maxsplit]]) -> list of strings\n",
      " |      \n",
      " |      Return a list of the words in the string S, using sep as the\n",
      " |      delimiter string.  If maxsplit is given, at most maxsplit\n",
      " |      splits are done. If sep is not specified or is None, any\n",
      " |      whitespace string is a separator and empty strings are removed\n",
      " |      from the result.\n",
      " |  \n",
      " |  splitlines(...)\n",
      " |      S.splitlines(keepends=False) -> list of strings\n",
      " |      \n",
      " |      Return a list of the lines in S, breaking at line boundaries.\n",
      " |      Line breaks are not included in the resulting list unless keepends\n",
      " |      is given and true.\n",
      " |  \n",
      " |  startswith(...)\n",
      " |      S.startswith(prefix[, start[, end]]) -> bool\n",
      " |      \n",
      " |      Return True if S starts with the specified prefix, False otherwise.\n",
      " |      With optional start, test S beginning at that position.\n",
      " |      With optional end, stop comparing S at that position.\n",
      " |      prefix can also be a tuple of strings to try.\n",
      " |  \n",
      " |  strip(...)\n",
      " |      S.strip([chars]) -> string or unicode\n",
      " |      \n",
      " |      Return a copy of the string S with leading and trailing\n",
      " |      whitespace removed.\n",
      " |      If chars is given and not None, remove characters in chars instead.\n",
      " |      If chars is unicode, S will be converted to unicode before stripping\n",
      " |  \n",
      " |  swapcase(...)\n",
      " |      S.swapcase() -> string\n",
      " |      \n",
      " |      Return a copy of the string S with uppercase characters\n",
      " |      converted to lowercase and vice versa.\n",
      " |  \n",
      " |  title(...)\n",
      " |      S.title() -> string\n",
      " |      \n",
      " |      Return a titlecased version of S, i.e. words start with uppercase\n",
      " |      characters, all remaining cased characters have lowercase.\n",
      " |  \n",
      " |  translate(...)\n",
      " |      S.translate(table [,deletechars]) -> string\n",
      " |      \n",
      " |      Return a copy of the string S, where all characters occurring\n",
      " |      in the optional argument deletechars are removed, and the\n",
      " |      remaining characters have been mapped through the given\n",
      " |      translation table, which must be a string of length 256 or None.\n",
      " |      If the table argument is None, no translation is applied and\n",
      " |      the operation simply removes the characters in deletechars.\n",
      " |  \n",
      " |  upper(...)\n",
      " |      S.upper() -> string\n",
      " |      \n",
      " |      Return a copy of the string S converted to uppercase.\n",
      " |  \n",
      " |  zfill(...)\n",
      " |      S.zfill(width) -> string\n",
      " |      \n",
      " |      Pad a numeric string S with zeros on the left, to fill a field\n",
      " |      of the specified width.  The string S is never truncated.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __new__ = <built-in method __new__ of type object>\n",
      " |      T.__new__(S, ...) -> a new object with type S, a subtype of T\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class list in module __builtin__:\n",
      "\n",
      "class list(object)\n",
      " |  list() -> new empty list\n",
      " |  list(iterable) -> new list initialized from iterable's items\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __add__(...)\n",
      " |      x.__add__(y) <==> x+y\n",
      " |  \n",
      " |  __contains__(...)\n",
      " |      x.__contains__(y) <==> y in x\n",
      " |  \n",
      " |  __delitem__(...)\n",
      " |      x.__delitem__(y) <==> del x[y]\n",
      " |  \n",
      " |  __delslice__(...)\n",
      " |      x.__delslice__(i, j) <==> del x[i:j]\n",
      " |      \n",
      " |      Use of negative indices is not supported.\n",
      " |  \n",
      " |  __eq__(...)\n",
      " |      x.__eq__(y) <==> x==y\n",
      " |  \n",
      " |  __ge__(...)\n",
      " |      x.__ge__(y) <==> x>=y\n",
      " |  \n",
      " |  __getattribute__(...)\n",
      " |      x.__getattribute__('name') <==> x.name\n",
      " |  \n",
      " |  __getitem__(...)\n",
      " |      x.__getitem__(y) <==> x[y]\n",
      " |  \n",
      " |  __getslice__(...)\n",
      " |      x.__getslice__(i, j) <==> x[i:j]\n",
      " |      \n",
      " |      Use of negative indices is not supported.\n",
      " |  \n",
      " |  __gt__(...)\n",
      " |      x.__gt__(y) <==> x>y\n",
      " |  \n",
      " |  __iadd__(...)\n",
      " |      x.__iadd__(y) <==> x+=y\n",
      " |  \n",
      " |  __imul__(...)\n",
      " |      x.__imul__(y) <==> x*=y\n",
      " |  \n",
      " |  __init__(...)\n",
      " |      x.__init__(...) initializes x; see help(type(x)) for signature\n",
      " |  \n",
      " |  __iter__(...)\n",
      " |      x.__iter__() <==> iter(x)\n",
      " |  \n",
      " |  __le__(...)\n",
      " |      x.__le__(y) <==> x<=y\n",
      " |  \n",
      " |  __len__(...)\n",
      " |      x.__len__() <==> len(x)\n",
      " |  \n",
      " |  __lt__(...)\n",
      " |      x.__lt__(y) <==> x<y\n",
      " |  \n",
      " |  __mul__(...)\n",
      " |      x.__mul__(n) <==> x*n\n",
      " |  \n",
      " |  __ne__(...)\n",
      " |      x.__ne__(y) <==> x!=y\n",
      " |  \n",
      " |  __repr__(...)\n",
      " |      x.__repr__() <==> repr(x)\n",
      " |  \n",
      " |  __reversed__(...)\n",
      " |      L.__reversed__() -- return a reverse iterator over the list\n",
      " |  \n",
      " |  __rmul__(...)\n",
      " |      x.__rmul__(n) <==> n*x\n",
      " |  \n",
      " |  __setitem__(...)\n",
      " |      x.__setitem__(i, y) <==> x[i]=y\n",
      " |  \n",
      " |  __setslice__(...)\n",
      " |      x.__setslice__(i, j, y) <==> x[i:j]=y\n",
      " |      \n",
      " |      Use  of negative indices is not supported.\n",
      " |  \n",
      " |  __sizeof__(...)\n",
      " |      L.__sizeof__() -- size of L in memory, in bytes\n",
      " |  \n",
      " |  append(...)\n",
      " |      L.append(object) -- append object to end\n",
      " |  \n",
      " |  count(...)\n",
      " |      L.count(value) -> integer -- return number of occurrences of value\n",
      " |  \n",
      " |  extend(...)\n",
      " |      L.extend(iterable) -- extend list by appending elements from the iterable\n",
      " |  \n",
      " |  index(...)\n",
      " |      L.index(value, [start, [stop]]) -> integer -- return first index of value.\n",
      " |      Raises ValueError if the value is not present.\n",
      " |  \n",
      " |  insert(...)\n",
      " |      L.insert(index, object) -- insert object before index\n",
      " |  \n",
      " |  pop(...)\n",
      " |      L.pop([index]) -> item -- remove and return item at index (default last).\n",
      " |      Raises IndexError if list is empty or index is out of range.\n",
      " |  \n",
      " |  remove(...)\n",
      " |      L.remove(value) -- remove first occurrence of value.\n",
      " |      Raises ValueError if the value is not present.\n",
      " |  \n",
      " |  reverse(...)\n",
      " |      L.reverse() -- reverse *IN PLACE*\n",
      " |  \n",
      " |  sort(...)\n",
      " |      L.sort(cmp=None, key=None, reverse=False) -- stable sort *IN PLACE*;\n",
      " |      cmp(x, y) -> -1, 0, 1\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __hash__ = None\n",
      " |  \n",
      " |  __new__ = <built-in method __new__ of type object>\n",
      " |      T.__new__(S, ...) -> a new object with type S, a subtype of T\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class tuple in module __builtin__:\n",
      "\n",
      "class tuple(object)\n",
      " |  tuple() -> empty tuple\n",
      " |  tuple(iterable) -> tuple initialized from iterable's items\n",
      " |  \n",
      " |  If the argument is a tuple, the return value is the same object.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __add__(...)\n",
      " |      x.__add__(y) <==> x+y\n",
      " |  \n",
      " |  __contains__(...)\n",
      " |      x.__contains__(y) <==> y in x\n",
      " |  \n",
      " |  __eq__(...)\n",
      " |      x.__eq__(y) <==> x==y\n",
      " |  \n",
      " |  __ge__(...)\n",
      " |      x.__ge__(y) <==> x>=y\n",
      " |  \n",
      " |  __getattribute__(...)\n",
      " |      x.__getattribute__('name') <==> x.name\n",
      " |  \n",
      " |  __getitem__(...)\n",
      " |      x.__getitem__(y) <==> x[y]\n",
      " |  \n",
      " |  __getnewargs__(...)\n",
      " |  \n",
      " |  __getslice__(...)\n",
      " |      x.__getslice__(i, j) <==> x[i:j]\n",
      " |      \n",
      " |      Use of negative indices is not supported.\n",
      " |  \n",
      " |  __gt__(...)\n",
      " |      x.__gt__(y) <==> x>y\n",
      " |  \n",
      " |  __hash__(...)\n",
      " |      x.__hash__() <==> hash(x)\n",
      " |  \n",
      " |  __iter__(...)\n",
      " |      x.__iter__() <==> iter(x)\n",
      " |  \n",
      " |  __le__(...)\n",
      " |      x.__le__(y) <==> x<=y\n",
      " |  \n",
      " |  __len__(...)\n",
      " |      x.__len__() <==> len(x)\n",
      " |  \n",
      " |  __lt__(...)\n",
      " |      x.__lt__(y) <==> x<y\n",
      " |  \n",
      " |  __mul__(...)\n",
      " |      x.__mul__(n) <==> x*n\n",
      " |  \n",
      " |  __ne__(...)\n",
      " |      x.__ne__(y) <==> x!=y\n",
      " |  \n",
      " |  __repr__(...)\n",
      " |      x.__repr__() <==> repr(x)\n",
      " |  \n",
      " |  __rmul__(...)\n",
      " |      x.__rmul__(n) <==> n*x\n",
      " |  \n",
      " |  count(...)\n",
      " |      T.count(value) -> integer -- return number of occurrences of value\n",
      " |  \n",
      " |  index(...)\n",
      " |      T.index(value, [start, [stop]]) -> integer -- return first index of value.\n",
      " |      Raises ValueError if the value is not present.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __new__ = <built-in method __new__ of type object>\n",
      " |      T.__new__(S, ...) -> a new object with type S, a subtype of T\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tuple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1299869600"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tuples + lists: slicing, concatination, indexing\n",
    "# only lists: reverse, sort, pop\n",
    "# only tuple: hash\n",
    "hash((1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myTuple = tuple([1])\n",
    "print myTuple\n",
    "type(myTuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myTuple = (1,)\n",
    "print myTuple\n",
    "type(myTuple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NLP', 'is', 'fun', '!']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ['is', 'NLP', 'fun', '?']\n",
    "tmp = words[0]\n",
    "words[0] = words[1]\n",
    "words[1] = tmp\n",
    "words[3] = '!'\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NLP', 'is', 'fun', '!']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ['is', 'NLP', 'fun', '?']\n",
    "words[0], words[1], words[3] = words[1], words[0], '!'\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function cmp in module __builtin__:\n",
      "\n",
      "cmp(...)\n",
      "    cmp(x, y) -> integer\n",
      "    \n",
      "    Return negative if x<y, zero if x==y, positive if x>y.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(cmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmp(3,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmp(9,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# can differentiate 3 cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 6)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The', 'dog', 'gave'],\n",
       " ['dog', 'gave', 'John'],\n",
       " ['gave', 'John', 'the'],\n",
       " ['John', 'the', 'newspaper']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = ['The', 'dog', 'gave', 'John', 'the', 'newspaper']\n",
    "n = 3\n",
    "[sent[i:i+n] for i in range(len(sent)-n+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The'], ['dog'], ['gave'], ['John'], ['the'], ['newspaper']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = ['The', 'dog', 'gave', 'John', 'the', 'newspaper']\n",
    "n = 1\n",
    "[sent[i:i+n] for i in range(len(sent)-n+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The', 'dog', 'gave', 'John', 'the', 'newspaper']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = ['The', 'dog', 'gave', 'John', 'the', 'newspaper']\n",
    "n = len(sent)\n",
    "[sent[i:i+n] for i in range(len(sent)-n+1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 7)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if (0):\n",
    "    print 'true!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true!\n"
     ]
    }
   ],
   "source": [
    "if (1):\n",
    "    print 'true!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true!\n"
     ]
    }
   ],
   "source": [
    "if ('foo'):\n",
    "    print 'true!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if (()):\n",
    "    print 'true!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true!\n"
     ]
    }
   ],
   "source": [
    "if ((1,2)):\n",
    "    print 'true!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true!\n"
     ]
    }
   ],
   "source": [
    "if (-1):\n",
    "    print 'true!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 8)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Monty' < 'Python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Z' < 'a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'z' < 'a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Monty' < 'Montague'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "('Monty', 1) < ('Monty', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "('Monty', 1) < ('Montague', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1, 'Monty') < (2, 'Montague')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 9)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'some whitespaced string'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a\n",
    "myStr = '  some    whitespaced string  '\n",
    "' '.join(myStr.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'some whitespaced string'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# b\n",
    "import re\n",
    "re.sub(r'\\s+', ' ', re.sub(r'^\\s+|\\s+$', '', myStr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 10)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'dog', 'the', 'gave', 'John', 'newspaper']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sortWords(words):\n",
    "    def cmp_len(word1, word2):\n",
    "        return cmp(len(word1), len(word2))\n",
    "    return sorted(words, cmp=cmp_len)\n",
    "\n",
    "sortWords(['The', 'dog', 'gave', 'John', 'the', 'newspaper'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 11)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'cat', 'gave', 'John', 'the', 'newspaper']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent1 = ['The', 'dog', 'gave', 'John', 'the', 'newspaper']\n",
    "sent2 = sent1\n",
    "sent1[1] = 'cat'\n",
    "sent2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'dog', 'gave', 'John', 'the', 'newspaper']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a\n",
    "sent1 = ['The', 'dog', 'gave', 'John', 'the', 'newspaper']\n",
    "sent2 = sent1[:]\n",
    "sent1[1] = 'cat'\n",
    "sent2\n",
    "# [:] -> copy list items, instead of creating reference to same list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The', 'monkey', 'gave', 'John', 'the', 'newspaper'],\n",
       " ['The', 'cat', 'miowed']]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# b\n",
    "text1 = [['The', 'dog', 'gave', 'John', 'the', 'newspaper'], ['The', 'cat', 'miowed']]\n",
    "text2 = text1[:]\n",
    "text1[0][1] = 'monkey'\n",
    "text2\n",
    "# did not copy inner lists, but references to them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function deepcopy in module copy:\n",
      "\n",
      "deepcopy(x, memo=None, _nil=[])\n",
      "    Deep copy operation on arbitrary Python objects.\n",
      "    \n",
      "    See the module's __doc__ string for more info.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# c\n",
    "from copy import deepcopy\n",
    "help(deepcopy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The', 'dog', 'gave', 'John', 'the', 'newspaper'], ['The', 'cat', 'miowed']]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = [['The', 'dog', 'gave', 'John', 'the', 'newspaper'], ['The', 'cat', 'miowed']]\n",
    "text3 = deepcopy(text1)\n",
    "text1[0][1] = 'monkey'\n",
    "text3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 12)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['', '', 'hello'], ['', '', 'hello'], ['', '', 'hello'], ['', '', 'hello']]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_table = [[''] * 3] * 4\n",
    "word_table[1][2] = \"hello\"\n",
    "word_table\n",
    "# multiplication adds references to the same list, not copies of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['', '', ''], ['', '', 'hello'], ['', '', ''], ['', '', '']]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_table = [['' for count1 in range(3)] for count2 in range(4)]\n",
    "word_table[1][2] = \"hello\"\n",
    "word_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 13)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['the', 'The', 'dog', 'cat'])\n",
      "set(['newspaper'])\n"
     ]
    }
   ],
   "source": [
    "word_vowels = [[]]\n",
    "words = ['The', 'dog', 'gave', 'John', 'the', 'newspaper', 'The', 'cat', 'miowed']\n",
    "for word in words:\n",
    "    if (len(word) > len(word_vowels)-1):\n",
    "        for index in range(len(word_vowels), len(word)+1):\n",
    "            word_vowels.append([])\n",
    "    num_vowels = len(re.findall(r'[aeiouAEIOU]', word))\n",
    "    if (num_vowels > len(word_vowels[len(word)])-1):\n",
    "        for index in range(len(word_vowels[len(word)]), num_vowels+1):\n",
    "            word_vowels[len(word)].append(set())\n",
    "    word_vowels[len(word)][num_vowels].add(word)\n",
    "print word_vowels[3][1]\n",
    "print word_vowels[9][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 14)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n",
      "[u'nati', u'aga', u'His', u'Phallu', u'Hezron', u'Carmi', u'Jemuel', u'Jamin', u'Ohad', u'Jachin', u'Shaul', u'Canaanitish', u'Gershon', u'Kohath', u'Merari', u'Zar', u'Hezron', u'Hamul', u'Tola', u'Phuvah', u'Job', u'Shimron', u'Sered', u'Jahleel', u'Din', u'Ziphion', u'Haggi', u'Shuni', u'Ezbon', u'Eri', u'Arodi', u'Areli', u'Jimnah', u'Ishuah', u'Isui', u'Beriah', u'Serah', u'Beriah', u'Heber', u'Malchiel', u'sixteen', u'Belah', u'Becher', u'Ashbel', u'Gera', u'Naaman', u'Ehi', u'Rosh', u'Muppim', u'Huppim', u'Ard', u'Hushim', u'Jahzeel', u'Guni', u'Jezer', u'Shillem', u'direct', u'presented', u'shepherds', u'occupation', u'fathe', u'shepherd', u'presented', u'occupation', u'shepherds', u'morever', u'pasture', u'activity', u'rulers', u'pilgrimage', u'attained', u'pilgrimage', u'Rameses', u'nourished', u'boug', u'faileth', u'fail', u'exchange', u'horses', u'bodies', u'lan', u'desolate', u'priests', u'priests', u'assigned', u'sow', u'increase', u'parts', u'saved', u'priests', u'multiplied', u'nigh', u'bed', u'si', u'strengthened', u'bed', u'issue', u'begettest', u'Padan', u'guiding', u'wittingly', u'Angel', u'redeemed', u'lads', u'remove', u'Not', u'Manass', u'last', u'excellency', u'dignity', u'excellency', u'pow', u'Unstable', u'excel', u'wentest', u'bed', u'defiledst', u'couch', u'instruments', u'cruelty', u'secret', u'assembly', u'honour', u'unit', u'selfwill', u'wall', u'fierce', u'cru', u'lion', u'whelp', u'prey', u'stooped', u'couched', u'lion', u'lion', u'rouse', u'sceptre', u'lawgiver', u'Shiloh', u'Binding', u'foal', u'colt', u'His', u'teeth', u'haven', u'haven', u'ships', u'Zidon', u'strong', u'couching', u'burdens', u'tribute', u'tribes', u'adder', u'path', u'biteth', u'horse', u'heels', u'rider', u'waited', u'salvation', u'overcome', u'overcome', u'last', u'royal', u'dainties', u'hind', u'loose', u'giveth', u'bough', u'bough', u'run', u'wa', u'archers', u'sorely', u'arms', u'strong', u'shepherd', u'blessings', u'blessings', u'blessings', u'breasts', u'blessings', u'blessings', u'progenitors', u'utmost', u'hil', u'crown', u'ravin', u'wolf', u'devour', u'prey', u'spoil', u'tribes', u'peop', u'purchase', u'commanding', u'bed', u'yielded', u'physicians', u'embalm', u'physicians', u'embalmed', u'embalm', u'past', u'elders', u'elders', u'chariots', u'horsemen', u'threshingfloor', u'Atad', u'lamentati', u'floor', u'Atad', u'Egyptia', u'Abelmizraim', u'requite', u'messenger', u'Forgive', u'forgive', u'meant', u'Machir', u'visit', u'visit', u'embalmed', u'coffin']\n"
     ]
    }
   ],
   "source": [
    "def novel10(text):\n",
    "    splitIndex = len(text) / 10\n",
    "    print [w for w in text[-splitIndex:] if w not in text[:-splitIndex]]\n",
    "from nltk.book import *\n",
    "novel10(text3)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 15)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",: 1\n",
      ".: 1\n",
      "a: 1\n",
      "and: 1\n",
      "as: 2\n",
      "cloud: 1\n",
      "lay: 1\n",
      "london: 1\n",
      "of: 3\n",
      "on: 1\n",
      "park: 1\n",
      "ragged: 1\n",
      "red: 1\n",
      "saffron: 1\n",
      "side: 1\n",
      "suburb: 1\n",
      "sunset: 2\n",
      "the: 2\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "def countWords(sent):\n",
    "    sent = sent.split()\n",
    "    fdist = nltk.FreqDist(w.lower() for w in sent)\n",
    "    for key in sorted(fdist.keys()):\n",
    "        print '%s: %d' % (key, fdist[key])\n",
    "countWords(' '.join(sent9))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 16)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "660"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a\n",
    "def gematria(word):\n",
    "    letter_vals = {'a':1, 'b':2, 'c':3, 'd':4, 'e':5, 'f':80, 'g':3, 'h':8, 'i':10, 'j':10, 'k':20, 'l':30, 'm':40, 'n':50, 'o':70, 'p':80, 'q':100, 'r':200, 's':300, 't':400, 'u':6, 'v':6, 'w':800, 'x':60, 'y':10, 'z':7}\n",
    "    return sum(letter_vals[l] for l in word if len(re.findall(r'[a-z]', l)) > 0)\n",
    "gematria('gematria')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1945-Truman.txt: 2\n",
      "set([u'outlook', u'eloquent'])\n",
      "\n",
      "1946-Truman.txt: 13\n",
      "set([u'retain', u'outlook', u'market'])\n",
      "\n",
      "1947-Truman.txt: 0\n",
      "set([])\n",
      "\n",
      "1948-Truman.txt: 2\n",
      "set([u'market'])\n",
      "\n",
      "1949-Truman.txt: 2\n",
      "set([u'market'])\n",
      "\n",
      "1950-Truman.txt: 1\n",
      "set([u'outlook'])\n",
      "\n",
      "1951-Truman.txt: 0\n",
      "set([])\n",
      "\n",
      "1953-Eisenhower.txt: 1\n",
      "set([u'market'])\n",
      "\n",
      "1954-Eisenhower.txt: 6\n",
      "set([u'retain', u'market'])\n",
      "\n",
      "1955-Eisenhower.txt: 3\n",
      "set([u'outlook', u'market'])\n",
      "\n",
      "1956-Eisenhower.txt: 1\n",
      "set([u'outlook'])\n",
      "\n",
      "1957-Eisenhower.txt: 2\n",
      "set([u'retain', u'market'])\n",
      "\n",
      "1958-Eisenhower.txt: 5\n",
      "set([u'retain', u'extra'])\n",
      "\n",
      "1959-Eisenhower.txt: 1\n",
      "set([u'outlook'])\n",
      "\n",
      "1960-Eisenhower.txt: 5\n",
      "set([u'outlook', u'eloquent', u'miraculous', u'philosophy'])\n",
      "\n",
      "1961-Kennedy.txt: 0\n",
      "set([])\n",
      "\n",
      "1962-Kennedy.txt: 11\n",
      "set([u'retain', u'market'])\n",
      "\n",
      "1963-Johnson.txt: 0\n",
      "set([])\n",
      "\n",
      "1963-Kennedy.txt: 5\n",
      "set([u'market', u'extra'])\n",
      "\n",
      "1964-Johnson.txt: 1\n",
      "set([u'market'])\n",
      "\n",
      "1965-Johnson-1.txt: 0\n",
      "set([])\n",
      "\n",
      "1965-Johnson-2.txt: 0\n",
      "set([])\n",
      "\n",
      "1966-Johnson.txt: 0\n",
      "set([])\n",
      "\n",
      "1967-Johnson.txt: 2\n",
      "set([u'outlook', u'extra'])\n",
      "\n",
      "1968-Johnson.txt: 3\n",
      "set([u'outlook', u'market'])\n",
      "\n",
      "1969-Johnson.txt: 0\n",
      "set([])\n",
      "\n",
      "1970-Nixon.txt: 0\n",
      "set([])\n",
      "\n",
      "1971-Nixon.txt: 1\n",
      "set([u'extra'])\n",
      "\n",
      "1972-Nixon.txt: 0\n",
      "set([])\n",
      "\n",
      "1973-Nixon.txt: 1\n",
      "set([u'philosophy'])\n",
      "\n",
      "1974-Nixon.txt: 0\n",
      "set([])\n",
      "\n",
      "1975-Ford.txt: 0\n",
      "set([])\n",
      "\n",
      "1976-Ford.txt: 3\n",
      "set([u'eloquent', u'extra'])\n",
      "\n",
      "1977-Ford.txt: 0\n",
      "set([])\n",
      "\n",
      "1978-Carter.txt: 1\n",
      "set([u'retain'])\n",
      "\n",
      "1979-Carter.txt: 2\n",
      "set([u'retain', u'extra'])\n",
      "\n",
      "1980-Carter.txt: 0\n",
      "set([])\n",
      "\n",
      "1981-Reagan.txt: 4\n",
      "set([u'market'])\n",
      "\n",
      "1982-Reagan.txt: 0\n",
      "set([])\n",
      "\n",
      "1983-Reagan.txt: 2\n",
      "set([u'market'])\n",
      "\n",
      "1984-Reagan.txt: 1\n",
      "set([u'market'])\n",
      "\n",
      "1985-Reagan.txt: 1\n",
      "set([u'market'])\n",
      "\n",
      "1986-Reagan.txt: 1\n",
      "set([u'squander'])\n",
      "\n",
      "1987-Reagan.txt: 1\n",
      "set([u'market'])\n",
      "\n",
      "1988-Reagan.txt: 2\n",
      "set([u'market', u'extra'])\n",
      "\n",
      "1989-Bush.txt: 1\n",
      "set([u'retain'])\n",
      "\n",
      "1990-Bush.txt: 2\n",
      "set([u'market', u'extra'])\n",
      "\n",
      "1991-Bush-1.txt: 0\n",
      "set([])\n",
      "\n",
      "1991-Bush-2.txt: 0\n",
      "set([])\n",
      "\n",
      "1992-Bush.txt: 3\n",
      "set([u'papers', u'market', u'extra'])\n",
      "\n",
      "1993-Clinton.txt: 1\n",
      "set([u'market'])\n",
      "\n",
      "1994-Clinton.txt: 2\n",
      "set([u'market'])\n",
      "\n",
      "1995-Clinton.txt: 1\n",
      "set([u'market'])\n",
      "\n",
      "1996-Clinton.txt: 2\n",
      "set([u'market'])\n",
      "\n",
      "1997-Clinton.txt: 1\n",
      "set([u'market'])\n",
      "\n",
      "1998-Clinton.txt: 4\n",
      "set([u'competency', u'market'])\n",
      "\n",
      "1999-Clinton.txt: 1\n",
      "set([u'extra'])\n",
      "\n",
      "2000-Clinton.txt: 3\n",
      "set([u'retina', u'miraculous', u'extra'])\n",
      "\n",
      "2001-GWBush-1.txt: 1\n",
      "set([u'philosophy'])\n",
      "\n",
      "2001-GWBush-2.txt: 0\n",
      "set([])\n",
      "\n",
      "2002-GWBush.txt: 0\n",
      "set([])\n",
      "\n",
      "2003-GWBush.txt: 3\n",
      "set([u'miraculous', u'market', u'extra'])\n",
      "\n",
      "2004-GWBush.txt: 2\n",
      "set([u'extra', u'papers'])\n",
      "\n",
      "2005-GWBush.txt: 2\n",
      "set([u'market', u'extra'])\n",
      "\n",
      "2006-GWBush.txt: 0\n",
      "set([])\n"
     ]
    }
   ],
   "source": [
    "# b\n",
    "for fileid in nltk.corpus.state_union.fileids():\n",
    "    words666 = [w.lower() for w in nltk.corpus.state_union.words(fileid) if w.isalpha() and gematria(w.lower()) == 666]\n",
    "    print '\\n%s: %d' % (fileid, len(words666))\n",
    "    print set(words666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "765\n",
      "set([u'partaking', u'poetry', u'against', u'authorizing', u'gratefully', u'thorough', u'operated', u'frightened', u'tells', u'mentor'])\n"
     ]
    }
   ],
   "source": [
    "# c\n",
    "import random\n",
    "def decode(text):\n",
    "    num = random.randint(1, 1000)\n",
    "    return num, set([w.lower() for w in text if w.isalpha() and gematria(w.lower()) == num])\n",
    "\n",
    "result = decode(text4)\n",
    "print result[0]\n",
    "print result[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 17)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u',', u'and', u'the', u'of', u'.', u'And', u'his', u'he', u'to', u';', u'unto', u'in', u'that', u'I', u'said', u'him', u'a', u'my', u'was', u'for', u'it', u'with', u'me', u'thou', u\"'\", u'is', u'thy', u's', u'thee', u'be', u'shall', u'they', u'all', u':', u'God', u'them', u'not', u'father', u'which', u'will', u'land', u'Jacob', u'came', u'her', u'LORD', u'were', u'she', u'Joseph', u'from', u'their']\n",
      "In beginning created heaven earth earth without form void darkness upon face deep Spirit moved upon face waters Let there light there light saw light good divided light darkness called light Day darkness called Night evening morning first day Let there firmament midst waters let divide waters waters made firmament divided waters under firmament waters above firmame so called firmament Heaven evening morning second day Let waters under heaven gathered together one place let dry appe so called dry Earth gathering together waters called Se saw good Let earth bring forth grass herb yielding seed fruit tree yielding fruit after\n"
     ]
    }
   ],
   "source": [
    "def shorten(text, n=20):\n",
    "    most_freq = nltk.FreqDist(text).most_common(n)\n",
    "    most_freq = [w for (w, num) in most_freq]\n",
    "    print most_freq\n",
    "    return [w for w in text if w not in most_freq]\n",
    "\n",
    "print ' '.join(shorten(text3, 50)[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 18)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fish', 'whale']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getWords(prop, value):\n",
    "    lexicon = [('fish', 'water animal', 'fish'), ('house', 'building', 'haus'), ('whale', 'water animal', 'wejl')]\n",
    "    if prop == 'meaning':\n",
    "        return [w for (w, m, p) in lexicon if m == value]\n",
    "    if prop == 'pronunciation':\n",
    "        return [w for (w, m, p) in lexicon if p == value]\n",
    "    \n",
    "getWords('meaning', 'water animal')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['house']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getWords('pronunciation', 'haus')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 19)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('lesser_rorqual.n.01'),\n",
       " Synset('killer_whale.n.01'),\n",
       " Synset('tortoise.n.01'),\n",
       " Synset('novel.n.01')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "list_syns = [wn.synset('minke_whale.n.01'), wn.synset('orca.n.01'), wn.synset('novel.n.01'), wn.synset('tortoise.n.01')]\n",
    "comp = wn.synset('right_whale.n.01')\n",
    "sorted(list_syns, lambda x,y: cmp(comp.shortest_path_distance(x), comp.shortest_path_distance(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 20)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['four', 'three', 'two', 'one']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sortWords(wordList):\n",
    "    fdist = nltk.FreqDist(wordList)\n",
    "    return fdist.keys()\n",
    "sortWords(['one', 'two', 'two', 'four', 'four', 'four', 'four', 'three', 'three', 'three'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 21)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'Sell',\n",
       " u'Allonbachuth',\n",
       " u'childr',\n",
       " u'gr',\n",
       " u'clusters',\n",
       " u'Togarmah',\n",
       " u'caused',\n",
       " u'badne',\n",
       " u'Matred',\n",
       " u'Gether',\n",
       " u'ceased',\n",
       " u'mules',\n",
       " u'Take',\n",
       " u'fearest',\n",
       " u'Ebal',\n",
       " u'likene',\n",
       " u'Husham',\n",
       " u'menservants',\n",
       " u'Ehi',\n",
       " u'sevens',\n",
       " u'Jimnah',\n",
       " u'Nod',\n",
       " u'Milcah',\n",
       " u'Peniel',\n",
       " u'tr',\n",
       " u'Avith',\n",
       " u'answered',\n",
       " u'preserved',\n",
       " u'Not',\n",
       " u'dukes',\n",
       " u'suffered',\n",
       " u'spee',\n",
       " u'Casluhim',\n",
       " u'Day',\n",
       " u'Mehujael',\n",
       " u'Feed',\n",
       " u'Whoso',\n",
       " u'Muppim',\n",
       " u'hadst',\n",
       " u'souls',\n",
       " u'fai',\n",
       " u'putting',\n",
       " u'breaketh',\n",
       " u'nourished',\n",
       " u'wagons',\n",
       " u'Mesopotamia',\n",
       " u'Abrah',\n",
       " u'Where',\n",
       " u'Mibsam',\n",
       " u'chesnut',\n",
       " u'knowest',\n",
       " u'Es',\n",
       " u'perceived',\n",
       " u'peop',\n",
       " u'Adbeel',\n",
       " u'And',\n",
       " u'presented',\n",
       " u'clothed',\n",
       " u'interpretations',\n",
       " u'Jobab',\n",
       " u'hous',\n",
       " u'Binding',\n",
       " u'joined',\n",
       " u'marvelled',\n",
       " u'daughers',\n",
       " u'Jetheth',\n",
       " u'Pison',\n",
       " u'guiding',\n",
       " u'Go',\n",
       " u'tru',\n",
       " u'buryingplace',\n",
       " u'Unto',\n",
       " u'Our',\n",
       " u'favoured',\n",
       " u'talked',\n",
       " u'Mamre',\n",
       " u'Hanoch',\n",
       " u'toucheth',\n",
       " u'repenteth',\n",
       " u'Midianites',\n",
       " u'Reu',\n",
       " u'compassed',\n",
       " u'honourable',\n",
       " u'creepeth',\n",
       " u'foals',\n",
       " u'Hadoram',\n",
       " u'tarried',\n",
       " u'Hebron',\n",
       " u'Tebah',\n",
       " u'sepulchre',\n",
       " u'espied',\n",
       " u'favour',\n",
       " u'Until',\n",
       " u'lights',\n",
       " u'Gaham',\n",
       " u'Jidlaph',\n",
       " u'Hear',\n",
       " u'Maachah',\n",
       " u'Put',\n",
       " u';',\n",
       " u'seemed',\n",
       " u'Have',\n",
       " u'pressed',\n",
       " u'Me',\n",
       " u'Huppim',\n",
       " u'Ephra',\n",
       " u'themselv',\n",
       " u'servants',\n",
       " u'Havilah',\n",
       " u'honour',\n",
       " u'hairs',\n",
       " u'leaped',\n",
       " u'kindled',\n",
       " u'Mizz',\n",
       " u'circumcis',\n",
       " u'youngest',\n",
       " u'Hagar',\n",
       " u'Woman',\n",
       " u'Mahanaim',\n",
       " u'dea',\n",
       " u'hast',\n",
       " u'Zeboim',\n",
       " u'bulls',\n",
       " u'My',\n",
       " u'Becher',\n",
       " u'Zeboiim',\n",
       " u'Zo',\n",
       " u'togeth',\n",
       " u'Shem',\n",
       " u'bou',\n",
       " u'women',\n",
       " u'Naphtuhim',\n",
       " u'concubi',\n",
       " u'Unstable',\n",
       " u'spices',\n",
       " u'changes',\n",
       " u'Riphath',\n",
       " u'named',\n",
       " u'Said',\n",
       " u'followed',\n",
       " u'Mehetabel',\n",
       " u'oversig',\n",
       " u'Assyr',\n",
       " u'When',\n",
       " u'marriages',\n",
       " u'erected',\n",
       " u'Shammah',\n",
       " u'Also',\n",
       " u'threshingfloor',\n",
       " u'tithes',\n",
       " u'Therefore',\n",
       " u'Asshur',\n",
       " u'Dishan',\n",
       " u'bre',\n",
       " u'Kor',\n",
       " u'isles',\n",
       " u'Zilpah',\n",
       " u'Assyria',\n",
       " u'doeth',\n",
       " u'Beor',\n",
       " u'Hul',\n",
       " u'walketh',\n",
       " u'bundles',\n",
       " u'asses',\n",
       " u'Bedad',\n",
       " u'sepulchres',\n",
       " u'longedst',\n",
       " u'wentest',\n",
       " u'reproa',\n",
       " u'angels',\n",
       " u'Ithran',\n",
       " u'Huz',\n",
       " u'Almighty',\n",
       " u'separated',\n",
       " u'sheweth',\n",
       " u'Kohath',\n",
       " u'Phallu',\n",
       " u'Asenath',\n",
       " u'waxed',\n",
       " u'healed',\n",
       " u'Mash',\n",
       " u'Bless',\n",
       " u'Leummim',\n",
       " u'Zillah',\n",
       " u'Ezbon',\n",
       " u'So',\n",
       " u'charged',\n",
       " u'Ziphion',\n",
       " u'needeth',\n",
       " u'appointed',\n",
       " u'Se',\n",
       " u'Perizzite',\n",
       " u'wrestled',\n",
       " u'shepherds',\n",
       " u'Now',\n",
       " u'Madai',\n",
       " u'refrained',\n",
       " u'Manass',\n",
       " u'meeteth',\n",
       " u'goest',\n",
       " u'Ashkenaz',\n",
       " u'Wherefore',\n",
       " u'flo',\n",
       " u'maidservants',\n",
       " u'believed',\n",
       " u'Chedorlaomer',\n",
       " u'speaketh',\n",
       " u'fle',\n",
       " u'spilled',\n",
       " u'lingered',\n",
       " u'Out',\n",
       " u'Lie',\n",
       " u'purchased',\n",
       " u'saith',\n",
       " u'Whereas',\n",
       " u'progenitors',\n",
       " u'pieces',\n",
       " u'escaped',\n",
       " u'heard',\n",
       " u'Abr',\n",
       " u'urged',\n",
       " u'Mahalath',\n",
       " u'Sheleph',\n",
       " u'stories',\n",
       " u'rods',\n",
       " u'habitations',\n",
       " u'Cause',\n",
       " u'spe',\n",
       " u'tak',\n",
       " u'!',\n",
       " u'journeyed',\n",
       " u'chariots',\n",
       " u'Thirty',\n",
       " u'inhabitants',\n",
       " u'LO',\n",
       " u'Who',\n",
       " u'nuts',\n",
       " u'Diklah',\n",
       " u',)',\n",
       " u'faults',\n",
       " u'Rebek',\n",
       " u'hou',\n",
       " u'hor',\n",
       " u'dwe',\n",
       " u'Zaavan',\n",
       " u'Isra',\n",
       " u'Why',\n",
       " u'Arvadite',\n",
       " u'merchantmen',\n",
       " u'mouths',\n",
       " u'Wilt',\n",
       " u'Nineveh',\n",
       " u'Joktan',\n",
       " u'halted',\n",
       " u'?)',\n",
       " u'fleddest',\n",
       " u'verified',\n",
       " u'Know',\n",
       " u'Jahzeel',\n",
       " u'fo',\n",
       " u'All',\n",
       " u'twins',\n",
       " u'branches',\n",
       " u'morter',\n",
       " u'speckl',\n",
       " u'drinketh',\n",
       " u'liveth',\n",
       " u'Eldaah',\n",
       " u'Moabites',\n",
       " u'rebuked',\n",
       " u'gavest',\n",
       " u'pleaseth',\n",
       " u'darkne',\n",
       " u'anoth',\n",
       " u'bakers',\n",
       " u'Er',\n",
       " u'pulled',\n",
       " u'reproved',\n",
       " u'Fill',\n",
       " u'Reumah',\n",
       " u'What',\n",
       " u'Drink',\n",
       " u'words',\n",
       " u'selfwill',\n",
       " u'dreamed',\n",
       " u'Paran',\n",
       " u'offerings',\n",
       " u'interpreted',\n",
       " u'held',\n",
       " u'sinning',\n",
       " u'committed',\n",
       " u'Hazo',\n",
       " u'rewarded',\n",
       " u'younge',\n",
       " u'birds',\n",
       " u'Kemuel',\n",
       " u'Hinder',\n",
       " u'Gerar',\n",
       " u'clo',\n",
       " u'possessions',\n",
       " u'mandrakes',\n",
       " u'lentiles',\n",
       " u'offeri',\n",
       " u'Zemarite',\n",
       " u'ships',\n",
       " u',',\n",
       " u'Here',\n",
       " u'embalmed',\n",
       " u'destroyed',\n",
       " u'Carmi',\n",
       " u'messes',\n",
       " u'womenservants',\n",
       " u'dunge',\n",
       " u'decreased',\n",
       " u'troubled',\n",
       " u'Machir',\n",
       " u'prisoners',\n",
       " u'Lest',\n",
       " u'There',\n",
       " u'Amalekites',\n",
       " u'Moreover',\n",
       " u'males',\n",
       " u'hunter',\n",
       " u'refused',\n",
       " u'Sojourn',\n",
       " u'obeyed',\n",
       " u'From',\n",
       " u'Serah',\n",
       " u'Can',\n",
       " u'sceptre',\n",
       " u'Ishuah',\n",
       " u'Arodi',\n",
       " u'killed',\n",
       " u'Tubalcain',\n",
       " u'sinners',\n",
       " u'feet',\n",
       " u'Eshban',\n",
       " u'Karnaim',\n",
       " u'Lehabim',\n",
       " u'Arphaxad',\n",
       " u'Pinon',\n",
       " u'Timna',\n",
       " u'horses',\n",
       " u'Lasha',\n",
       " u'Say',\n",
       " u'shekels',\n",
       " u'Zohar',\n",
       " u'garmen',\n",
       " u'carcases',\n",
       " u'Phara',\n",
       " u'longeth',\n",
       " u'reigned',\n",
       " u'Hazezontamar',\n",
       " u'Rosh',\n",
       " u'Zerah',\n",
       " u'Pharez',\n",
       " u'anointedst',\n",
       " u'Luz',\n",
       " u'Beerlahairoi',\n",
       " u'Except',\n",
       " u'Send',\n",
       " u'skins',\n",
       " u'hundredfo',\n",
       " u'Lud',\n",
       " u'hanged',\n",
       " u'befell',\n",
       " u'findest',\n",
       " u'giveth',\n",
       " u'ev',\n",
       " u'opened',\n",
       " u'Malchiel',\n",
       " u'kids',\n",
       " u'Ohad',\n",
       " u'ringstraked',\n",
       " u'vessels',\n",
       " u'strangers',\n",
       " u'Rephaims',\n",
       " u'Terah',\n",
       " u'Obal',\n",
       " u'Bozrah',\n",
       " u'Edomites',\n",
       " u'Eliezer',\n",
       " u'ri',\n",
       " u'Zebulun',\n",
       " u'Manasseh',\n",
       " u'Egy',\n",
       " u'sheddeth',\n",
       " u'Sheba',\n",
       " u'This',\n",
       " u'hang',\n",
       " u'deceived',\n",
       " u'spies',\n",
       " u'Swear',\n",
       " u'Stand',\n",
       " u'grapes',\n",
       " u'placed',\n",
       " u'heads',\n",
       " u'pris',\n",
       " u'Jetur',\n",
       " u'Fulfil',\n",
       " u'planted',\n",
       " u'Forasmuch',\n",
       " u'Ammon',\n",
       " u'created',\n",
       " u'Hori',\n",
       " u'deprived',\n",
       " u'Iram',\n",
       " u'Shebah',\n",
       " u'leanfleshed',\n",
       " u'seekest',\n",
       " u'seest',\n",
       " u'called',\n",
       " u'prospered',\n",
       " u'Anamim',\n",
       " u'faileth',\n",
       " u'Emins',\n",
       " u'grisl',\n",
       " u'curseth',\n",
       " u'waited',\n",
       " u'Speak',\n",
       " u'Even',\n",
       " u'Shaveh',\n",
       " u'asswaged',\n",
       " u'Edar',\n",
       " u'Guni',\n",
       " u'grisled',\n",
       " u'Amalek',\n",
       " u'Aner',\n",
       " u'knoweth',\n",
       " u'comforted',\n",
       " u'visited',\n",
       " u'Machpelah',\n",
       " u'barr',\n",
       " u'Timnah',\n",
       " u'reached',\n",
       " u'Ashbel',\n",
       " u'visions',\n",
       " u'seeth',\n",
       " u'lieth',\n",
       " u'Sered',\n",
       " u'Jebusites',\n",
       " u'citi',\n",
       " u'beguiled',\n",
       " u'aileth',\n",
       " u'entreated',\n",
       " u'Irad',\n",
       " u'households',\n",
       " u'Zaphnathpaaneah',\n",
       " u'beari',\n",
       " u'worshipped',\n",
       " u'Whose',\n",
       " u'Anah',\n",
       " u'blossoms',\n",
       " u'catt',\n",
       " u'Zidon',\n",
       " u'Do',\n",
       " u'eyes',\n",
       " u'Jehovahjireh',\n",
       " u'stars',\n",
       " u'serva',\n",
       " u'Ophir',\n",
       " u'mayest',\n",
       " u'Abimelech',\n",
       " u'Jeush',\n",
       " u'Dinhabah',\n",
       " u'conceived',\n",
       " u'herds',\n",
       " u'Sabtech',\n",
       " u'abated',\n",
       " u'appe',\n",
       " u'storehouses',\n",
       " u'ste',\n",
       " u'Set',\n",
       " u'morever',\n",
       " u'Potipherah',\n",
       " u'EleloheIsrael',\n",
       " u'Only',\n",
       " u'nations',\n",
       " u'coats',\n",
       " u'See',\n",
       " u'slimepits',\n",
       " u'husba',\n",
       " u'fruits',\n",
       " u'Lahairoi',\n",
       " u'Yet',\n",
       " u'repented',\n",
       " u'communing',\n",
       " u'proceedeth',\n",
       " u'tongues',\n",
       " u'Horites',\n",
       " u'Pau',\n",
       " u'remained',\n",
       " u'thistles',\n",
       " u'dainties',\n",
       " u'Peace',\n",
       " u'Tarshish',\n",
       " u'Beersheba',\n",
       " u'jewels',\n",
       " u'rained',\n",
       " u'shrubs',\n",
       " u'Ezer',\n",
       " u'magnified',\n",
       " u'firmame',\n",
       " u'Neither',\n",
       " u'Shaul',\n",
       " u'Then',\n",
       " u'overthrew',\n",
       " u'pursued',\n",
       " u'Kenaz',\n",
       " u'After',\n",
       " u'Egyptia',\n",
       " u'officers',\n",
       " u'Hiddekel',\n",
       " u'priests',\n",
       " u'wandered',\n",
       " u'Behold',\n",
       " u'overtook',\n",
       " u'They',\n",
       " u'laughed',\n",
       " u'Ask',\n",
       " u'Gihon',\n",
       " u'Dothan',\n",
       " u'Spirit',\n",
       " u'Kenites',\n",
       " u'Aram',\n",
       " u'Seir',\n",
       " u'vestures',\n",
       " u'comest',\n",
       " u'Hadad',\n",
       " u'Thy',\n",
       " u'bereaved',\n",
       " u'shewed',\n",
       " u'measures',\n",
       " u'troughs',\n",
       " u'wells',\n",
       " u'Up',\n",
       " u'Hadar',\n",
       " u'butlers',\n",
       " u'Abidah',\n",
       " u'seasons',\n",
       " u'Isa',\n",
       " u'Kadmonites',\n",
       " u'fetcht',\n",
       " u'Twelve',\n",
       " u'mightier',\n",
       " u'Benam',\n",
       " u'camest',\n",
       " u'garments',\n",
       " u'nostrils',\n",
       " u'consumed',\n",
       " u'archers',\n",
       " u'Some',\n",
       " u'kn',\n",
       " u'counted',\n",
       " u'looked',\n",
       " u'Shillem',\n",
       " u'Ahuzzath',\n",
       " u'Shinar',\n",
       " u'Earth',\n",
       " u'bondmen',\n",
       " u'If',\n",
       " u'How',\n",
       " u'trembled',\n",
       " u'Beno',\n",
       " u'laws',\n",
       " u'stones',\n",
       " u'Hai',\n",
       " u'Zibeon',\n",
       " u'twel',\n",
       " u'Ham',\n",
       " u'departing',\n",
       " u'arrayed',\n",
       " u'Kedemah',\n",
       " u'liest',\n",
       " u'generatio',\n",
       " u'Gilead',\n",
       " u'Nebajoth',\n",
       " u'Erech',\n",
       " u'compasseth',\n",
       " u'fatfleshed',\n",
       " u'Amorites',\n",
       " u'Tamar',\n",
       " u'wor',\n",
       " u'imagined',\n",
       " u'Jabal',\n",
       " u'weapons',\n",
       " u'We',\n",
       " u'Shobal',\n",
       " u'Shur',\n",
       " u'prevailed',\n",
       " u'giants',\n",
       " u'(',\n",
       " u'Return',\n",
       " u'Atad',\n",
       " u'Ephron',\n",
       " u'failed',\n",
       " u'Peradventure',\n",
       " u'judged',\n",
       " u'attained',\n",
       " u'Bera',\n",
       " u'Shemeber',\n",
       " u'thousands',\n",
       " u'?',\n",
       " u'lighted',\n",
       " u'Pildash',\n",
       " u'magicians',\n",
       " u'wrestlings',\n",
       " u'silv',\n",
       " u'loved',\n",
       " u'natio',\n",
       " u'Heth',\n",
       " u'Canaanites',\n",
       " u'trees',\n",
       " u'yielded',\n",
       " u'spi',\n",
       " u'While',\n",
       " u'ones',\n",
       " u'hid',\n",
       " u'bracelets',\n",
       " u'Heber',\n",
       " u'Discern',\n",
       " u'savoury',\n",
       " u'Zepho',\n",
       " u'hil',\n",
       " u'having',\n",
       " u'firstborn',\n",
       " u'princes',\n",
       " u'devoured',\n",
       " u'Because',\n",
       " u'boug',\n",
       " u'Angel',\n",
       " u'countries',\n",
       " u'grap',\n",
       " u'begettest',\n",
       " u'fainted',\n",
       " u'sacrifices',\n",
       " u'hasted',\n",
       " u'avenged',\n",
       " u'Eshcol',\n",
       " u'physicians',\n",
       " u'Padanaram',\n",
       " u'journeys',\n",
       " u'Mezahab',\n",
       " u'Calah',\n",
       " u'slayeth',\n",
       " u'bak',\n",
       " u'generations',\n",
       " u'ears',\n",
       " u'waters',\n",
       " u'strengthened',\n",
       " u'sto',\n",
       " u'seas',\n",
       " u'Hittites',\n",
       " u'signs',\n",
       " u'Moab',\n",
       " u'Abide',\n",
       " u'Pass',\n",
       " u'observed',\n",
       " u'Sabtah',\n",
       " u'crieth',\n",
       " u'hastened',\n",
       " u'gutters',\n",
       " u'Esek',\n",
       " u'Tola',\n",
       " u'knees',\n",
       " u'Jabbok',\n",
       " u'lambs',\n",
       " u'That',\n",
       " u'Sichem',\n",
       " u'Hereby',\n",
       " u'tents',\n",
       " u'Forgive',\n",
       " u'Jac',\n",
       " u'colours',\n",
       " u'Jubal',\n",
       " u'dost',\n",
       " u'strakes',\n",
       " u'Egyptians',\n",
       " u'Cush',\n",
       " u'cru',\n",
       " u'beasts',\n",
       " u'gathered',\n",
       " u'chode',\n",
       " u'multiplied',\n",
       " u'Moriah',\n",
       " u'elders',\n",
       " u'Be',\n",
       " u'Ephah',\n",
       " u'fathe',\n",
       " u'loins',\n",
       " u'comi',\n",
       " u'Remain',\n",
       " u'His',\n",
       " u'Thus',\n",
       " u'windows',\n",
       " u'Chaldees',\n",
       " u'Thahash',\n",
       " u'cities',\n",
       " u'Cainan',\n",
       " u'Merari',\n",
       " u'horsemen',\n",
       " u'Hazarmaveth',\n",
       " u'Gatam',\n",
       " u'Haggi',\n",
       " u'Eliphaz',\n",
       " u'Give',\n",
       " u'Yea',\n",
       " u'damsels',\n",
       " u'Mishma',\n",
       " u'Blessed',\n",
       " u'rams',\n",
       " u'fulfilled',\n",
       " u'Bring',\n",
       " u'became',\n",
       " u'faces',\n",
       " u'hith',\n",
       " u'Sitnah',\n",
       " u'Zar',\n",
       " u'asked',\n",
       " u'Ye',\n",
       " u'Mesha',\n",
       " u'cakes',\n",
       " u'co',\n",
       " u'Succoth',\n",
       " u'appeared',\n",
       " u'deeds',\n",
       " u'Calneh',\n",
       " u'spake',\n",
       " u'Jezer',\n",
       " u'Lamech',\n",
       " u'Gera',\n",
       " u'mercies',\n",
       " u'Asshurim',\n",
       " u'kings',\n",
       " u'biteth',\n",
       " u'famished',\n",
       " u'Hamul',\n",
       " u'fema',\n",
       " u'Buz',\n",
       " u'Ajah',\n",
       " u'Edom',\n",
       " u'fountains',\n",
       " u'Get',\n",
       " u'Ishbak',\n",
       " u'But',\n",
       " u'.',\n",
       " u'purposing',\n",
       " u'poured',\n",
       " u'Moreh',\n",
       " u'En',\n",
       " u'Hushim',\n",
       " u'entered',\n",
       " u'Zebul',\n",
       " u'kine',\n",
       " u'oth',\n",
       " u'shoulders',\n",
       " u'Elbethel',\n",
       " u'families',\n",
       " u'Areli',\n",
       " u'Galeed',\n",
       " u'digged',\n",
       " u'blessings',\n",
       " u'Shed',\n",
       " u'Penuel',\n",
       " u'mocking',\n",
       " u'Whence',\n",
       " u'Shepho',\n",
       " u'lives',\n",
       " u'Haran',\n",
       " u'Night',\n",
       " u'Thorns',\n",
       " u'Accad',\n",
       " u'towns',\n",
       " u'doth',\n",
       " u'Nahath',\n",
       " u'sheepshearers',\n",
       " u'To',\n",
       " u'possessi',\n",
       " u'Beware',\n",
       " u'lovest',\n",
       " u'Two',\n",
       " u'Euphrates',\n",
       " u'Hitti',\n",
       " u'Cursed',\n",
       " u'Philistim',\n",
       " u'Salem',\n",
       " u'Beriah',\n",
       " u'Achbor',\n",
       " u'sle',\n",
       " u'Kittim',\n",
       " u'messengers',\n",
       " u'changed',\n",
       " u'Samlah',\n",
       " u'played',\n",
       " u'riv',\n",
       " u'ir',\n",
       " u'Almodad',\n",
       " u'Esau',\n",
       " u'rulers',\n",
       " u'Gather',\n",
       " u'heels',\n",
       " u'commanded',\n",
       " u'cometh',\n",
       " u'Nay',\n",
       " u'Tell',\n",
       " u'sheaves',\n",
       " u'Birsha',\n",
       " u'feebler',\n",
       " u'flocks',\n",
       " u'Elparan',\n",
       " u'Belah',\n",
       " u')',\n",
       " u'things',\n",
       " u'began',\n",
       " u'Spake',\n",
       " u'Lotan',\n",
       " u'parts',\n",
       " u'bands',\n",
       " u'handmaids',\n",
       " u'Tidal',\n",
       " u'daughters',\n",
       " u'Appoint',\n",
       " u'booths',\n",
       " u'Padan',\n",
       " u'Escape',\n",
       " u'Aran',\n",
       " u'endued',\n",
       " u'commended',\n",
       " u'Midian',\n",
       " u'persons',\n",
       " u'fowls',\n",
       " u'firstlings',\n",
       " u'Haste',\n",
       " u'Admah',\n",
       " u'Kiriathaim',\n",
       " u'traffick',\n",
       " u'subtil',\n",
       " u'colts',\n",
       " u'thoughts',\n",
       " u'kid',\n",
       " u'asketh',\n",
       " u'Adah',\n",
       " u'Sod',\n",
       " u'loveth',\n",
       " u'Slay',\n",
       " u'Enmishpat',\n",
       " u'remaineth',\n",
       " u'Is',\n",
       " u'Cheran',\n",
       " u'It',\n",
       " u'Phichol',\n",
       " u'Iscah',\n",
       " u'Jaalam',\n",
       " u'Manahath',\n",
       " u'hearkened',\n",
       " u'thi',\n",
       " u'In',\n",
       " u'Zarah',\n",
       " u'Perizzites',\n",
       " u'builded',\n",
       " u'discerned',\n",
       " u'bodies',\n",
       " u'She',\n",
       " u'Sarai',\n",
       " u'plagues',\n",
       " u'Gomorrah',\n",
       " u'badest',\n",
       " u'womenservan',\n",
       " u'gods',\n",
       " u'hands',\n",
       " u'numbering',\n",
       " u'daughte',\n",
       " u'laded',\n",
       " u'bakemeats',\n",
       " u'Ashteroth',\n",
       " u'Bilhah',\n",
       " u'Methusael',\n",
       " u'years',\n",
       " u'plains',\n",
       " u'meanest',\n",
       " u'Happy',\n",
       " u'servan',\n",
       " u'Kirjatharba',\n",
       " u'camels',\n",
       " u'hills',\n",
       " u'tim',\n",
       " u'hated',\n",
       " u'supplanted',\n",
       " u'Masrekah',\n",
       " u'Eri',\n",
       " u'ewes',\n",
       " u'Amal',\n",
       " u'nati',\n",
       " u'Naphtali',\n",
       " u'Surely',\n",
       " u'Phut',\n",
       " u'Arbah',\n",
       " u'By',\n",
       " u'boys',\n",
       " u'Cherubims',\n",
       " u'mountains',\n",
       " u'On',\n",
       " u'Din',\n",
       " u'mocked',\n",
       " u'increased',\n",
       " u'Oh',\n",
       " u'Thou',\n",
       " u'Of',\n",
       " u'Salah',\n",
       " u'fath',\n",
       " u'stooped',\n",
       " u'wives',\n",
       " u'awaked',\n",
       " u'Sidon',\n",
       " u'findeth',\n",
       " u'lads',\n",
       " u'aprons',\n",
       " u'Perizzit',\n",
       " u'Resen',\n",
       " u'emptied',\n",
       " u'droves',\n",
       " u'dreams',\n",
       " u'ruled',\n",
       " u'Bashemath',\n",
       " u'daught',\n",
       " u'Tiras',\n",
       " u'wiv',\n",
       " u'With',\n",
       " u'Chesed',\n",
       " u'baskets',\n",
       " u'lamentati',\n",
       " u'Ard',\n",
       " u'Are',\n",
       " u'served',\n",
       " u'Fear',\n",
       " u'Shalt',\n",
       " u'stretched',\n",
       " u'canst',\n",
       " u'numbered',\n",
       " u'burdens',\n",
       " u'Keturah',\n",
       " u'wombs',\n",
       " u'Phuvah',\n",
       " u'divineth',\n",
       " u'fathers',\n",
       " u'Ishmeelites',\n",
       " u'shew',\n",
       " u'reviv',\n",
       " u'vowedst',\n",
       " u'travailed',\n",
       " u'images',\n",
       " u'pillows',\n",
       " u'enemies',\n",
       " u'saidst',\n",
       " u'delivered',\n",
       " u'bones',\n",
       " u'Hast',\n",
       " u'Hemam',\n",
       " u'gard',\n",
       " u'Hirah',\n",
       " u'Ludim',\n",
       " u'sowed',\n",
       " u'Lift',\n",
       " u'Let',\n",
       " u'denied',\n",
       " u'earrings',\n",
       " u'handfuls',\n",
       " u'Fifteen',\n",
       " u'communed',\n",
       " u'He',\n",
       " u'goats',\n",
       " u'Heaven',\n",
       " u'intreated',\n",
       " u'Look',\n",
       " u'rul',\n",
       " u'Uz',\n",
       " u'Raamah',\n",
       " u'tribes',\n",
       " u'Arise',\n",
       " u'Bethel',\n",
       " u'Bow',\n",
       " u'Euphrat',\n",
       " u'Kenizzites',\n",
       " u'pla',\n",
       " u'Potiphar',\n",
       " u'weig',\n",
       " u';)',\n",
       " u'Naamah',\n",
       " u'Hebrews',\n",
       " u'gifts',\n",
       " u'sawest',\n",
       " u'Cast',\n",
       " u'ribs',\n",
       " u'months',\n",
       " u'oa',\n",
       " u'blessi',\n",
       " u'sakes',\n",
       " u'Gomer',\n",
       " u'Tubal',\n",
       " u'standest',\n",
       " ...}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def unknownWords(text, vocab):\n",
    "    return set(text).difference(set(vocab))\n",
    "unknownWords(text3, nltk.corpus.words.words())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 22)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In', 'the', 'beginning', 'God', 'created', 'the', 'heaven', 'and', 'the', 'earth']\n",
      "['earth', 'beginning', 'heaven', 'the', 'the', 'the', 'In', 'and', 'God', 'created']\n",
      "['God', 'created', 'and', 'the', 'the', 'the', 'beginning', 'earth', 'In', 'heaven']\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "print sent3[:-1]\n",
    "print sorted(sent3[:-1], key=itemgetter(1))\n",
    "print sorted(sent3[:-1], key=itemgetter(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class itemgetter in module operator:\n",
      "\n",
      "class itemgetter(__builtin__.object)\n",
      " |  itemgetter(item, ...) --> itemgetter object\n",
      " |  \n",
      " |  Return a callable object that fetches the given item(s) from its operand.\n",
      " |  After f = itemgetter(2), the call f(r) returns r[2].\n",
      " |  After g = itemgetter(2, 5, 3), the call g(r) returns (r[2], r[5], r[3])\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __call__(...)\n",
      " |      x.__call__(...) <==> x(...)\n",
      " |  \n",
      " |  __getattribute__(...)\n",
      " |      x.__getattribute__('name') <==> x.name\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __new__ = <built-in method __new__ of type object>\n",
      " |      T.__new__(S, ...) -> a new object with type S, a subtype of T\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(itemgetter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h\n",
      "hallo\n"
     ]
    }
   ],
   "source": [
    "i = itemgetter(0)\n",
    "print i('hallo')\n",
    "print i(['hallo', 'welt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 23)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cat'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "def insert(trie, key, value):\n",
    "    if key:\n",
    "        first, rest = key[0], key[1:]\n",
    "        if first not in trie:\n",
    "            trie[first] = {}\n",
    "        insert(trie[first], rest, value)\n",
    "    else:\n",
    "        trie['value'] = value\n",
    "        \n",
    "trie = nltk.defaultdict(dict)\n",
    "insert(trie, 'chat', 'cat')\n",
    "insert(trie, 'chien', 'dog')\n",
    "insert(trie, 'chair', 'flesh')\n",
    "trie['c']['h']['a']['t']['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no value found\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "def lookup(trie, key):\n",
    "    if len(key) == 0:\n",
    "        if 'value' in trie:\n",
    "            result = trie['value']\n",
    "            return result\n",
    "        elif (len(trie) == 1):\n",
    "            keys = trie.keys()\n",
    "            return lookup(trie[keys[0]], '')\n",
    "        else:\n",
    "            return 'no value found'\n",
    "    else:\n",
    "        if (key[0] in trie):\n",
    "            return lookup(trie[key[0]], key[1:])\n",
    "        else:\n",
    "            return 'no value found'\n",
    "\n",
    "print lookup(trie, 'ch')      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 24)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 25)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function edit_distance in module nltk.metrics.distance:\n",
      "\n",
      "edit_distance(s1, s2, transpositions=False)\n",
      "    Calculate the Levenshtein edit-distance between two strings.\n",
      "    The edit distance is the number of characters that need to be\n",
      "    substituted, inserted, or deleted, to transform s1 into s2.  For\n",
      "    example, transforming \"rain\" to \"shine\" requires three steps,\n",
      "    consisting of two substitutions and one insertion:\n",
      "    \"rain\" -> \"sain\" -> \"shin\" -> \"shine\".  These operations could have\n",
      "    been done in other orders, but at least three steps are needed.\n",
      "    \n",
      "    This also optionally allows transposition edits (e.g., \"ab\" -> \"ba\"),\n",
      "    though this is disabled by default.\n",
      "    \n",
      "    :param s1, s2: The strings to be analysed\n",
      "    :param transpositions: Whether to allow transposition edits\n",
      "    :type s1: str\n",
      "    :type s2: str\n",
      "    :type transpositions: bool\n",
      "    :rtype int\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(nltk.edit_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.edit_distance('kitten', 'sitting', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 26)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a\n",
    "def catalan_recursive(n):\n",
    "    if (n == 0):\n",
    "        return 1\n",
    "    i = 0\n",
    "    result = 0\n",
    "    original_n = n\n",
    "    while i < original_n:\n",
    "        result += catalan_recursive(i) * catalan_recursive(n-1)\n",
    "        n -= 1\n",
    "        i += 1\n",
    "    return result\n",
    "\n",
    "catalan_recursive(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# b\n",
    "def catalan_dynamic(n, lookup={0:1}):\n",
    "    result = 0\n",
    "    if n == 0:\n",
    "        return 1\n",
    "    for i in range(n):\n",
    "        if i not in lookup:\n",
    "            lookup[i] = catalan_dynamic(i, lookup)\n",
    "        if n-1 not in lookup:\n",
    "            lookup[n-1] = catalan_dynamic(n-1, lookup)\n",
    "        result += lookup[i] * lookup[n-1]    \n",
    "        n -= 1\n",
    "    return result\n",
    "\n",
    "catalan_dynamic(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.89065578542\n",
      "0.000288574442266\n"
     ]
    }
   ],
   "source": [
    "# c\n",
    "from timeit import Timer\n",
    "t = Timer(lambda: catalan_recursive(10))\n",
    "print t.timeit(number=10)\n",
    "t = Timer(lambda: catalan_dynamic(10))\n",
    "print t.timeit(number=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 27)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 28)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 29)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cat'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "trie = nltk.defaultdict(dict)\n",
    "insert(trie, 'chat', 'cat')\n",
    "insert(trie, 'chien', 'dog')\n",
    "insert(trie, 'chair', 'flesh')\n",
    "insert(trie, 'chic', 'stylish')\n",
    "trie['c']['h']['a']['t']['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chair: 'flesh'\n",
      "---t: 'cat'\n",
      "--ic: 'stylish'\n",
      "---en: 'dog'\n"
     ]
    }
   ],
   "source": [
    "def pprint_trie(trie, line=''):\n",
    "    if 'value' in trie:\n",
    "        print line + ': \\'' + trie['value'] + '\\''\n",
    "        return\n",
    "    for index, key in enumerate(sorted(trie.keys())):\n",
    "        if (index == 0):\n",
    "            pprint_trie(trie[key], line + key)\n",
    "        else:\n",
    "            pprint_trie(trie[key], ('-' * len(line)) + key)\n",
    "\n",
    "pprint_trie(trie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 30)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.1709714487\n",
      "[ Mob Dic by Herm Melv 1851 ] ETY . ( Suppl by a Late Consu Ush to a Gramm School ) The pale Ush -- threadb in coat , heart , body , and brain ; I see him now . He was ever dusti his old lexicons and gramm , with a queer handk , mockingl embellishe with all the gay flags of all the known nations of the world . He loved to dust his old gramm ; it someh mildl reminde him of his mortality . \" While you take in hand to school others , and to teach them by what name a whale - fish is to be called in our tongue leaving out , through ignoranc , the letter H , which almo alone maket the significat of the word , you deliver that which is not true .\" -- HAC \" WHALE . ... Sw . and Dan . HVAL . This animal is named from roundn or rolling ; for in Dan . HVALT is arched or vaulte .\" -- WE ' S DIC \" WHALE . ... It is more immediatel from the Dut . and Ger . WALLEN ;\n"
     ]
    }
   ],
   "source": [
    "def lookup_unique(key, trie, unique='', buffer_unique=''):\n",
    "    if len(key) == 0:\n",
    "        if len(buffer_unique) > 0:\n",
    "            return buffer_unique\n",
    "        else:  \n",
    "            return unique\n",
    "    if len(trie[key[0]]) == 1:\n",
    "        if len(buffer_unique) > 0:\n",
    "            new_buffer_unique = buffer_unique\n",
    "        else:\n",
    "            new_buffer_unique = unique + key[0]\n",
    "        return lookup_unique(key[1:], trie[key[0]], unique + key[0], new_buffer_unique)\n",
    "    return lookup_unique(key[1:], trie[key[0]], unique + key[0])\n",
    "        \n",
    "\n",
    "def compress(text):          \n",
    "    trie = nltk.defaultdict(dict)\n",
    "    for word in text:\n",
    "        insert(trie, word, word)\n",
    "    return [lookup_unique(w, trie) for w in text]\n",
    "\n",
    "compressed = compress(text1)\n",
    "from __future__ import division\n",
    "print (100.0/len(''.join(text1))) * len(''.join(compressed))\n",
    "print ' '.join(compressed[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.4444444444\n",
      "I t b G c t h a t e .\n"
     ]
    }
   ],
   "source": [
    "compressed = compress(sent3)\n",
    "print (100.0/len(''.join(sent3))) * len(''.join(compressed))\n",
    "print ' '.join(compressed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 31)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\xef\\xbb\\xbfWeb-Based E-Assessment Beyond Multiple-Choice: The Application of', 'PHP- and HTML5 Technologies to Different Testing Formats', \"Documentation  Master's Thesis in  Linguistics and Web Technology\", 'presented to the Faculty of Foreign Languages and Cultures at the', 'Philipps-Universit\\xc3\\xa4t Marburg  by    Julia Neumann from Naumburg', '(Germany) Marburg, 2015 Contents         List of Abbreviations   3 1', 'Introduction    4 2       User Guide      5 3       Overall', 'Organization of the Code        7 3.1     General Design of the', 'JavaScript Components     9 4       Implementation of the Testing', 'Formats   11 4.1     Crossword       11 4.2     Dynamic Multiple-']\n"
     ]
    }
   ],
   "source": [
    "def load(fileName):\n",
    "    f = open(fileName + '.txt')\n",
    "    return f.read()\n",
    "raw = load('corpus')\n",
    "import textwrap\n",
    "wrapped = textwrap.wrap(raw)\n",
    "print wrapped[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿Web-Based E-Assessment Beyond  Multiple-Choice: The Application  of\n",
      "PHP-   and   HTML5   Technologies   to   Different   Testing   Formats\n",
      "Documentation  Master's  Thesis  in  Linguistics  and  Web  Technology\n",
      "presented to  the Faculty  of Foreign  Languages and  Cultures at  the\n",
      "Philipps-Universität  Marburg   by  Julia    Neumann  from   Naumburg\n",
      "(Germany)  Marburg,   2015  Contents   List  of   Abbreviations  3   1\n",
      "Introduction     4     2      User     Guide      5      3     Overall\n",
      "Organization   of   the   Code   7   3.1   General   Design   of   the\n",
      "JavaScript   Components   9   4   Implementation    of   the   Testing\n",
      "Formats    11    4.1    Crossword    11    4.2    Dynamic    Multiple-\n",
      "Choice   13    4.3    Drag-and-Drop    15   5     Database   Structure\n",
      "17   6    General   Features     19   6.1    Index   Page     19   6.2\n",
      "Contact  Page   20  6.3    Color  Changer   20  6.4    Inline  Editing\n",
      "and    Deletion    21    6.5    Exporting    Tests    22    References\n",
      "25   Appendix    I:    Database    Structure   26     Declaration   of\n",
      "Authorship       27       List       of       Abbreviations       AJAX\n",
      "Asynchronous      JavaScript      and      XML      CSS      Cascading\n",
      "Style     Sheets      DOM     Document      Object     Model      HTML\n",
      "Hypertext     Markup     Language     JPEG      Joint     Photographic\n",
      "Experts       Group       MVC       Model-View-Controller       MySQLi\n",
      "MySQL    Improved    PHP     PHP:    Hypertext    Preprocessor     PNG\n",
      "Portable     Network      Graphics      SQL       Structured     Query\n",
      "Language      SVG       Scalable       Vector        Graphics      XML\n",
      "Extensible  Markup   Language  1    Introduction  This   documentation\n",
      "provides an overview of an application  developed for the creation and\n",
      "management of web-based assessment  tasks in three different  formats.\n",
      "The application consists  of a user-friendly  interface to a  database\n",
      "structure for storing the created tests and  allows its users not only\n",
      "to generate  new tests,   but also  to  edit,   delete, view,  and run\n",
      "existing tests.  Thus, it  constitutes  a  tool that  can be   used by\n"
     ]
    }
   ],
   "source": [
    "def justify(wrapped_text):\n",
    "    line_length = max(len(line) for line in wrapped_text)\n",
    "    for line in wrapped_text:\n",
    "        words = line.split()\n",
    "        num_chars = sum(len(word) for word in words)\n",
    "        num_spaces = line_length - num_chars\n",
    "        num_slots = len(words) - 1\n",
    "        fixed_spaces = int(num_spaces / num_slots)\n",
    "        spaces = 0\n",
    "        for index, word in enumerate(words[:-1]):\n",
    "            word += ' ' * fixed_spaces\n",
    "            spaces += fixed_spaces\n",
    "            words[index] = word\n",
    "            \n",
    "        while num_spaces - spaces > 0:\n",
    "            remainder = (num_spaces - spaces) % num_slots\n",
    "            chunk_size = int(len(words) / (remainder + 1))\n",
    "            chunk = 0\n",
    "            for index, word in enumerate(words[:-1]):\n",
    "                if remainder and chunk == chunk_size:\n",
    "                    word += ' '\n",
    "                    spaces += 1\n",
    "                    chunk = 0\n",
    "                else:    \n",
    "                    chunk += 1\n",
    "                words[index] = word\n",
    "            \n",
    "        print ''.join(words)\n",
    "        \n",
    "justify(wrapped[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 32)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274 :  [u'``', u'So', u'that', u'the', u'man', u'should', u'not', u'have', u'thoughts', u'of', u'grandeur', u',', u'and', u'become', u'lifted', u'up', u',', u'as', u'if', u'he', u'had', u'no', u'lord', u',', u'because', u'of', u'the', u'dominion', u'that', u'had', u'been', u'given', u'to', u'him', u',', u'and', u'the', u'freedom', u',', u'fall', u'into', u'sin', u'against', u'God', u'his', u'Creator', u',', u'overstepping', u'his', u'bounds', u',', u'and', u'take', u'up', u'an', u'attitude', u'of', u'self-conceited', u'arrogance', u'towards', u'God', u',', u'a', u'law', u'was', u'given', u'him', u'by', u'God', u',', u'that', u'he', u'might', u'know', u'that', u'he', u'had', u'for', u'lord', u'the', u'lord', u'of', u'all', u'.'] \n",
      "\n",
      "304 :  [u'But', u'He', u'set', u'a', u'bound', u'to', u'his', u'(', u'state', u'of', u')', u'sin', u',', u'by', u'interposing', u'death', u',', u'and', u'thus', u'causing', u'sin', u'to', u'cease', u',', u'putting', u'an', u'end', u'to', u'it', u'by', u'the', u'dissolution', u'of', u'the', u'flesh', u',', u'which', u'should', u'take', u'place', u'in', u'the', u'earth', u',', u'so', u'that', u'man', u',', u'ceasing', u'at', u'length', u'to', u'live', u'in', u'sin', u',', u'and', u'dying', u'to', u'it', u',', u'might', u'live', u'to', u'God', u\"''\", u'.'] \n",
      "\n",
      "383 :  [u'What', u'otherwise', u'could', u'``', u'the', u'lawyer', u',', u'doctor', u',', u'minister', u',', u'the', u'men', u'of', u'science', u'and', u'letters', u\"''\", u'do', u'when', u'told', u'that', u'they', u'had', u'``', u'become', u'the', u'cherubim', u'and', u'seraphim', u'and', u'the', u'three', u'archangels', u'who', u'stood', u'before', u'the', u'golden', u'throne', u'of', u'the', u'merchant', u',', u'and', u'continually', u'cried', u',', u\"'\", u'Holy', u',', u'holy', u',', u'holy', u'is', u'the', u'Almighty', u'Dollar', u\"'\", u'``', u'?', u'?'] \n",
      "\n",
      "401 :  [u'We', u'have', u'not', u'the', u'leisure', u',', u'or', u'the', u'patience', u',', u'or', u'the', u'skill', u',', u'to', u'comprehend', u'what', u'was', u'working', u'in', u'the', u'mind', u'and', u'heart', u'of', u'a', u'then', u'recent', u'graduate', u'from', u'the', u'Harvard', u'Divinity', u'School', u'who', u'would', u'muster', u'the', u'audacity', u'to', u'contradict', u'his', u'most', u'formidable', u'instructor', u',', u'the', u'majesterial', u'Andrews', u'Norton', u',', u'by', u'saying', u'that', u',', u'while', u'he', u'believed', u'Jesus', u'``', u'like', u'other', u'religious', u'teachers', u\"''\", u',', u'worked', u'miracles', u',', u'``', u'I', u'see', u'not', u'how', u'a', u'miracle', u'proves', u'a', u'doctrine', u\"''\", u'.'] \n",
      "\n",
      "406 :  [u'At', u'one', u'time', u'I', u'became', u'disturbed', u'in', u'the', u'faith', u'in', u'which', u'I', u'had', u'grown', u'up', u'by', u'the', u'apparent', u'inroads', u'being', u'made', u'upon', u'both', u'Old', u'and', u'New', u'Testaments', u'by', u'a', u'``', u'Higher', u'Criticism', u\"''\", u'of', u'the', u'Bible', u',', u'to', u'refute', u'which', u'I', u'felt', u'the', u'need', u'of', u'a', u'better', u'knowledge', u'of', u'Hebrew', u'and', u'of', u'archaeology', u',', u'for', u'it', u'seemed', u'to', u'me', u'that', u'to', u'pull', u'out', u'some', u'of', u'the', u'props', u'of', u'our', u'faith', u'was', u'to', u'weaken', u'the', u'entire', u'structure', u'.'] \n",
      "\n",
      "417 :  [u'The', u'outcome', u'of', u'such', u'an', u'experiment', u'has', u'been', u'in', u'due', u'time', u'the', u'acceptance', u'of', u'the', u'Bible', u'as', u'the', u'Word', u'of', u'God', u'inspired', u'in', u'a', u'sense', u'utterly', u'different', u'from', u'any', u'merely', u'human', u'book', u',', u'and', u'with', u'it', u'the', u'acceptance', u'of', u'our', u'Lord', u'Jesus', u'Christ', u'as', u'the', u'only', u'begotten', u'Son', u'of', u'God', u',', u'Son', u'of', u'Man', u'by', u'the', u'Virgin', u'Mary', u',', u'the', u'Saviour', u'of', u'the', u'world', u'.'] \n",
      "\n",
      "418 :  [u'I', u'believe', u',', u'therefore', u',', u'that', u'we', u'are', u'without', u'exception', u'sinners', u',', u'by', u'nature', u'alienated', u'from', u'God', u',', u'and', u'that', u'Jesus', u'Christ', u',', u'the', u'Son', u'of', u'God', u',', u'came', u'to', u'earth', u',', u'the', u'representative', u'Head', u'of', u'a', u'new', u'race', u',', u'to', u'die', u'upon', u'the', u'cross', u'and', u'pay', u'the', u'penalty', u'of', u'the', u'sin', u'of', u'the', u'world', u',', u'and', u'that', u'he', u'who', u'thus', u'receives', u'Christ', u'as', u'his', u'personal', u'Saviour', u'is', u'``', u'born', u'again', u\"''\", u'spiritually', u',', u'with', u'new', u'privileges', u',', u'appetites', u',', u'and', u'affections', u',', u'destined', u'to', u'live', u'and', u'grow', u'in', u'His', u'likeness', u'forever', u'.'] \n",
      "\n",
      "657 :  [u'Although', u'the', u'primary', u'mathematical', u'properties', u'of', u'the', u'middle', u'number', u'at', u'the', u'center', u'of', u'the', u'Lo', u'Shu', u',', u'and', u'the', u'interrelation', u'of', u'all', u'the', u'other', u'numbers', u'to', u'it', u',', u'might', u'seem', u'enough', u'to', u'account', u'for', u'the', u'deep', u'fascination', u'which', u'the', u'Lo', u'Shu', u'held', u'for', u'the', u'Old', u'Chinese', u'philosophers', u',', u'this', u'was', u'actually', u'only', u'a', u'beginning', u'of', u'wonders', u'.'] \n",
      "\n",
      "964 :  [u'Presumably', u',', u'if', u'the', u'reverse', u'is', u'the', u'case', u'and', u'the', u'good', u'effect', u'is', u'more', u'certain', u'than', u'the', u'evil', u'result', u'that', u'may', u'be', u'forthcoming', u',', u'not', u'only', u'must', u'the', u'good', u'and', u'the', u'evil', u'be', u'prudentially', u'weighed', u'and', u'found', u'proportionate', u',', u'but', u'also', u'calculation', u'of', u'the', u'probabilities', u'and', u'of', u'the', u'degree', u'of', u'certainty', u'or', u'uncertainty', u'in', u'the', u'good', u'or', u'evil', u'effect', u'must', u'be', u'taken', u'into', u'account', u'.'] \n",
      "\n",
      "1258 :  [u'We', u'should', u'recall', u'the', u'number', u'of', u'movements', u'for', u'the', u'service', u'of', u'mankind', u'which', u'arose', u'from', u'the', u'kindred', u'Evangelicalism', u'of', u'the', u'British', u'Isles', u'and', u'the', u'Pietism', u'of', u'the', u'Continent', u'of', u'Europe', u'--', u'among', u'them', u'prison', u'reform', u',', u'anti-slavery', u'measures', u',', u'legislation', u'for', u'the', u'alleviation', u'of', u'conditions', u'of', u'labour', u',', u'the', u'Inner', u'Mission', u',', u'and', u'the', u'Red', u'Cross', u'.'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "def summarize(text_sents, n):\n",
    "    from operator import itemgetter\n",
    "    freqDist = nltk.FreqDist([w.lower() for sent in text_sents for w in sent])\n",
    "    scoresSents = [(sum(freqDist[word] for word in sent), index, sent) for (index, sent) in enumerate(text_sents)]\n",
    "    sortByFreq = sorted(scoresSents, key=itemgetter(0), reverse=True)[:n]\n",
    "    sortByIndex = sorted(sortByFreq, key=itemgetter(1))\n",
    "    for (freq, index, sent) in sortByIndex:\n",
    "        print index, ': ', sent, '\\n'\n",
    "    \n",
    "from nltk.corpus import brown\n",
    "summarize(brown.sents(categories='religion'), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Exercise 33)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 34)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 35)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 36)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AANI\n",
      "ABAC\n",
      "NACE\n",
      "ICED\n"
     ]
    }
   ],
   "source": [
    "def word_square(n):\n",
    "    # works only if n < 5, with 5 exceeds maximum recursion callstack\n",
    "    # TODO: Do this iteratively to avoid the callstack issue?\n",
    "    from nltk.corpus import words\n",
    "    myWords = [word.upper() for word in filter(lambda w: len(w) == n, words.words())] # get all words of length n\n",
    "    \n",
    "    square = []\n",
    "    skipWords = [[] for i in range(n)] # cache for words that have already been tested at position i\n",
    "    \n",
    "    def check_against_square(word): # checks if current state of square would allow to add word to it\n",
    "        if word in square:\n",
    "            return False\n",
    "        for (index, square_word) in enumerate(square):\n",
    "            if (word[index] != square_word[len(square)]):\n",
    "                return False\n",
    "        return True\n",
    "    \n",
    "    def add_word(): # recursively adds / removes words from square until solution is found\n",
    "        if len(square) == n:\n",
    "            return True\n",
    "        for word in myWords:\n",
    "            if len(square) == n:\n",
    "                return True\n",
    "            if (word not in skipWords[len(square)]) and check_against_square(word): # add the word to square if it hasn't been tested unsuccessfully already and if it fits \n",
    "                square.append(word)\n",
    "                add_word()\n",
    "        if len(square) != n and len(square) != 0:   \n",
    "            skipWords[len(square) - 1].append(square.pop()) # add word to cache\n",
    "            for i in range(len(square) + 1, n): # reset the following parts of the cache\n",
    "                skipWords[i] = []\n",
    "            add_word()\n",
    "        return False\n",
    "            \n",
    "        \n",
    "    if add_word():\n",
    "        for word in square:\n",
    "            print word\n",
    "    else:\n",
    "        print 'No square found :/'\n",
    "            \n",
    "word_square(4)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAL\n",
      "ABA\n",
      "LAB\n"
     ]
    }
   ],
   "source": [
    "word_square(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
